{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NAS - Optuna\n",
    "\n",
    "- **Authored by:** Matheus Ferreira Silva \n",
    "- **GitHub:**: https://github.com/MatheusFS-dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Async CUDA allocator\n",
    "os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'\n",
    "\n",
    "# If cuDNN autotune fails, fall back to a safe (but slower) algorithm.\n",
    "os.environ[\"XLA_FLAGS\"] = \"--xla_gpu_strict_conv_algorithm_picker=false\"\n",
    "\n",
    "# Allow TensorFlow to allocate GPU memory as needed\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from _imports import * # Centralized file containing all imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. GPU Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify GPU to use (e.g., GPU 0)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "troo.get_gpu_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Run Parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOTAL_NUM_PORTS = 100\n",
    "\n",
    "observed_ports_list = [3, 4, 5, 6, 7, 10, 15]\n",
    "batch_sizes = [64, 128, 256, 64, 64, 64, 64]\n",
    "\n",
    "model_paths = [\n",
    "    \"./results/models/tcnn/optuna_study_3_ports/models/trial_128.keras\",\n",
    "    \"./results/models/tcnn/optuna_study_4_ports/models/trial_158.keras\",\n",
    "    \"./results/models/tcnn/optuna_study_5_ports/models/trial_149.keras\",\n",
    "    \"./results/models/tcnn/optuna_study_6_ports/models/trial_145.keras\",\n",
    "    \"./results/models/tcnn/optuna_study_7_ports/models/trial_16.keras\",\n",
    "    \"./results/models/tcnn/optuna_study_10_ports/models/trial_173.keras\",\n",
    "    \"./results/models/tcnn/optuna_study_15_ports/models/trial_13.keras\",\n",
    "]\n",
    "\n",
    "scalers = [\n",
    "    StandardScaler(),\n",
    "    StandardScaler(),\n",
    "    StandardScaler(),\n",
    "    StandardScaler(),\n",
    "    StandardScaler(),\n",
    "    StandardScaler(),\n",
    "    MinMaxScaler(feature_range=(0, 1)),\n",
    "]\n",
    "\n",
    "\n",
    "THRESHOLD = 0.95\n",
    "SNR_LINEAR = 1.25\n",
    "\n",
    "mixed_precision.set_global_policy(\"mixed_float16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_DIR = troo.create_run_directory(prefix=\"tcnn_op_\")\n",
    "print(f\"Run directory: {RUN_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------- Load the dataset in matlab format -------------------- #\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "kappa0_mu1_m0 = scipy.io.loadmat(\"./data/w1_u1_n100/SNR_events_W1.0_U1_N100_kappa1.0e-16_mu1.0_m0.0.mat\")[\"SNR_events\"]\n",
    "kappa0_mu1_m2 = scipy.io.loadmat(\"./data/w1_u1_n100/SNR_events_W1.0_U1_N100_kappa1.0e-16_mu1.0_m2.0.mat\")[\"SNR_events\"]\n",
    "kappa0_mu1_m50 = scipy.io.loadmat(\"./data/w1_u1_n100/SNR_events_W1.0_U1_N100_kappa1.0e-16_mu1.0_m50.0.mat\")[\"SNR_events\"]\n",
    "kappa0_mu2_m50 = scipy.io.loadmat(\"./data/w1_u1_n100/SNR_events_W1.0_U1_N100_kappa1.0e-16_mu2.0_m50.0.mat\")[\"SNR_events\"]\n",
    "kappa0_mu5_m50 = scipy.io.loadmat(\"./data/w1_u1_n100/SNR_events_W1.0_U1_N100_kappa1.0e-16_mu5.0_m50.0.mat\")[\"SNR_events\"]\n",
    "kappa5_mu1_m0 = scipy.io.loadmat(\"./data/w1_u1_n100/SNR_events_W1.0_U1_N100_kappa5.0e+00_mu1.0_m0.0.mat\")[\"SNR_events\"]\n",
    "kappa5_mu1_m2 = scipy.io.loadmat(\"./data/w1_u1_n100/SNR_events_W1.0_U1_N100_kappa5.0e+00_mu1.0_m2.0.mat\")[\"SNR_events\"]\n",
    "kappa5_mu1_m50 = scipy.io.loadmat(\"./data/w1_u1_n100/SNR_events_W1.0_U1_N100_kappa5.0e+00_mu1.0_m50.0.mat\")[\"SNR_events\"]\n",
    "kappa5_mu2_m0 = scipy.io.loadmat(\"./data/w1_u1_n100/SNR_events_W1.0_U1_N100_kappa5.0e+00_mu2.0_m0.0.mat\")[\"SNR_events\"]\n",
    "kappa5_mu2_m2 = scipy.io.loadmat(\"./data/w1_u1_n100/SNR_events_W1.0_U1_N100_kappa5.0e+00_mu2.0_m2.0.mat\")[\"SNR_events\"]\n",
    "kappa5_mu2_m50 = scipy.io.loadmat(\"./data/w1_u1_n100/SNR_events_W1.0_U1_N100_kappa5.0e+00_mu2.0_m50.0.mat\")[\"SNR_events\"]\n",
    "kappa5_mu5_m0 = scipy.io.loadmat(\"./data/w1_u1_n100/SNR_events_W1.0_U1_N100_kappa5.0e+00_mu5.0_m0.0.mat\")[\"SNR_events\"]\n",
    "kappa5_mu5_m2 = scipy.io.loadmat(\"./data/w1_u1_n100/SNR_events_W1.0_U1_N100_kappa5.0e+00_mu5.0_m2.0.mat\")[\"SNR_events\"]\n",
    "kappa5_mu5_m50 = scipy.io.loadmat(\"./data/w1_u1_n100/SNR_events_W1.0_U1_N100_kappa5.0e+00_mu5.0_m50.0.mat\")[\"SNR_events\"]\n",
    "\n",
    "# ————————————— Split the data into 10% training and 90% testing ————————————— #\n",
    "\n",
    "# kappa0_mu1_m0\n",
    "perm = rng.permutation(kappa0_mu1_m0.shape[0])\n",
    "n_test = int(0.9*kappa0_mu1_m0.shape[0])\n",
    "kappa0_mu1_m0_test = kappa0_mu1_m0[perm[:n_test]]\n",
    "kappa0_mu1_m0 = kappa0_mu1_m0[perm[n_test:]]\n",
    "\n",
    "# kappa0_mu1_m2\n",
    "perm = rng.permutation(kappa0_mu1_m2.shape[0])\n",
    "n_test = int(0.9*kappa0_mu1_m2.shape[0])\n",
    "kappa0_mu1_m2_test = kappa0_mu1_m2[perm[:n_test]]\n",
    "kappa0_mu1_m2 = kappa0_mu1_m2[perm[n_test:]]\n",
    "\n",
    "# kappa0_mu1_m50\n",
    "perm = rng.permutation(kappa0_mu1_m50.shape[0])\n",
    "n_test = int(0.9*kappa0_mu1_m50.shape[0])\n",
    "kappa0_mu1_m50_test = kappa0_mu1_m50[perm[:n_test]]\n",
    "kappa0_mu1_m50 = kappa0_mu1_m50[perm[n_test:]]\n",
    "\n",
    "# kappa0_mu2_m50\n",
    "perm = rng.permutation(kappa0_mu2_m50.shape[0])\n",
    "n_test = int(0.9*kappa0_mu2_m50.shape[0])\n",
    "kappa0_mu2_m50_test = kappa0_mu2_m50[perm[:n_test]]\n",
    "kappa0_mu2_m50 = kappa0_mu2_m50[perm[n_test:]]\n",
    "\n",
    "# kappa0_mu5_m50\n",
    "perm = rng.permutation(kappa0_mu5_m50.shape[0])\n",
    "n_test = int(0.9*kappa0_mu5_m50.shape[0])\n",
    "kappa0_mu5_m50_test = kappa0_mu5_m50[perm[:n_test]]\n",
    "kappa0_mu5_m50 = kappa0_mu5_m50[perm[n_test:]]\n",
    "\n",
    "# kappa5_mu1_m0\n",
    "perm = rng.permutation(kappa5_mu1_m0.shape[0])\n",
    "n_test = int(0.9*kappa5_mu1_m0.shape[0])\n",
    "kappa5_mu1_m0_test = kappa5_mu1_m0[perm[:n_test]]\n",
    "kappa5_mu1_m0 = kappa5_mu1_m0[perm[n_test:]]\n",
    "\n",
    "# kappa5_mu1_m2\n",
    "perm = rng.permutation(kappa5_mu1_m2.shape[0])\n",
    "n_test = int(0.9*kappa5_mu1_m2.shape[0])\n",
    "kappa5_mu1_m2_test = kappa5_mu1_m2[perm[:n_test]]\n",
    "kappa5_mu1_m2 = kappa5_mu1_m2[perm[n_test:]]\n",
    "\n",
    "# kappa5_mu1_m50\n",
    "perm = rng.permutation(kappa5_mu1_m50.shape[0])\n",
    "n_test = int(0.9*kappa5_mu1_m50.shape[0])\n",
    "kappa5_mu1_m50_test = kappa5_mu1_m50[perm[:n_test]]\n",
    "kappa5_mu1_m50 = kappa5_mu1_m50[perm[n_test:]]\n",
    "\n",
    "# kappa5_mu2_m0\n",
    "perm = rng.permutation(kappa5_mu2_m0.shape[0])\n",
    "n_test = int(0.9*kappa5_mu2_m0.shape[0])\n",
    "kappa5_mu2_m0_test = kappa5_mu2_m0[perm[:n_test]]\n",
    "kappa5_mu2_m0 = kappa5_mu2_m0[perm[n_test:]]\n",
    "\n",
    "# kappa5_mu2_m2\n",
    "perm = rng.permutation(kappa5_mu2_m2.shape[0])\n",
    "n_test = int(0.9*kappa5_mu2_m2.shape[0])\n",
    "kappa5_mu2_m2_test = kappa5_mu2_m2[perm[:n_test]]\n",
    "kappa5_mu2_m2 = kappa5_mu2_m2[perm[n_test:]]\n",
    "\n",
    "# kappa5_mu2_m50\n",
    "perm = rng.permutation(kappa5_mu2_m50.shape[0])\n",
    "n_test = int(0.9*kappa5_mu2_m50.shape[0])\n",
    "kappa5_mu2_m50_test = kappa5_mu2_m50[perm[:n_test]]\n",
    "kappa5_mu2_m50 = kappa5_mu2_m50[perm[n_test:]]\n",
    "\n",
    "# kappa5_mu5_m0\n",
    "perm = rng.permutation(kappa5_mu5_m0.shape[0])\n",
    "n_test = int(0.9*kappa5_mu5_m0.shape[0])\n",
    "kappa5_mu5_m0_test = kappa5_mu5_m0[perm[:n_test]]\n",
    "kappa5_mu5_m0 = kappa5_mu5_m0[perm[n_test:]]\n",
    "\n",
    "# kappa5_mu5_m2\n",
    "perm = rng.permutation(kappa5_mu5_m2.shape[0])\n",
    "n_test = int(0.9*kappa5_mu5_m2.shape[0])\n",
    "kappa5_mu5_m2_test = kappa5_mu5_m2[perm[:n_test]]\n",
    "kappa5_mu5_m2 = kappa5_mu5_m2[perm[n_test:]]\n",
    "\n",
    "# kappa5_mu5_m50\n",
    "perm = rng.permutation(kappa5_mu5_m50.shape[0])\n",
    "n_test = int(0.9*kappa5_mu5_m50.shape[0])\n",
    "kappa5_mu5_m50_test = kappa5_mu5_m50[perm[:n_test]]\n",
    "kappa5_mu5_m50 = kappa5_mu5_m50[perm[n_test:]]\n",
    "\n",
    "# ————————————— Concatenate all training subsamples along axis=0 ————————————— #\n",
    "dataset = np.concatenate(\n",
    "    [\n",
    "        kappa0_mu1_m0,\n",
    "        kappa0_mu1_m2,\n",
    "        kappa0_mu1_m50,\n",
    "        kappa0_mu2_m50,\n",
    "        kappa0_mu5_m50,\n",
    "        kappa5_mu1_m0,\n",
    "        kappa5_mu1_m2,\n",
    "        kappa5_mu1_m50,\n",
    "        kappa5_mu2_m0,\n",
    "        kappa5_mu2_m2,\n",
    "        kappa5_mu2_m50,\n",
    "        kappa5_mu5_m0,\n",
    "        kappa5_mu5_m2,\n",
    "        kappa5_mu5_m50,\n",
    "    ],\n",
    "    axis=0,\n",
    ")\n",
    "\n",
    "print(f\"Original dataset shape: {dataset.shape}\")\n",
    "\n",
    "# Subsample data\n",
    "# dataset = dataset[: int(0.01 * dataset.shape[0]), :]\n",
    "\n",
    "print(f\"Shape of the data after configuration: {dataset.shape}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Getters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6. Implementation getters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_observed_ports(sinr_data, num_observed_ports, total_ports):\n",
    "    \"\"\"\n",
    "    Extracts SINR values for the specified number of observed ports.\n",
    "\n",
    "    The function selects a subset of SINR data by identifying equally spaced ports based on the\n",
    "    number of observed ports specified. It returns the SINR values for these observed ports and\n",
    "    their corresponding indices.\n",
    "\n",
    "    Args:\n",
    "        sinr_data (numpy.ndarray): A 2D array where each row represents an observation and each column\n",
    "                                   represents a port with its corresponding SINR values.\n",
    "        num_observed_ports (int): The number of observed ports to select from the SINR data.\n",
    "        total_ports (int): The total number of ports in the SINR data.\n",
    "\n",
    "    Returns:\n",
    "        observed_sinr (numpy.ndarray): A 2D array containing the SINR values for the observed ports.\n",
    "        observed_indices (numpy.ndarray): A 1D array of the indices corresponding to the observed ports.\n",
    "    \"\"\"\n",
    "    observed_indices = np.linspace(0, total_ports - 1, num_observed_ports, dtype=int)\n",
    "    observed_sinr = sinr_data[:, observed_indices]\n",
    "\n",
    "    return observed_sinr, observed_indices\n",
    "\n",
    "\n",
    "def getOP(\n",
    "    observed_indices: np.ndarray,\n",
    "    predicted_values: np.ndarray,\n",
    "    true_values: np.ndarray,\n",
    "    threshold: float,\n",
    "    snr_linear: float,\n",
    "    total_ports: int,\n",
    ") -> float:\n",
    "    \"\"\"Estimate the outage probability for regression models.\n",
    "\n",
    "    This function compares the predicted and observed signal values at different\n",
    "    channels (ports) and determines whether the chosen signal is above a given threshold.\n",
    "    The outage probability is then computed as the proportion of times the signal falls\n",
    "    below this threshold.\n",
    "\n",
    "    Args:\n",
    "        observed_indices (np.ndarray): Indices of the observed ports (channels).\n",
    "        predicted_values (np.ndarray): Matrix of predicted values for each sample.\n",
    "        true_values (np.ndarray): Ground-truth values for each port.\n",
    "        threshold (float): Threshold value for determining outage.\n",
    "        snr_linear (float): Signal-to-noise ratio in linear scale.\n",
    "\n",
    "    Returns:\n",
    "        float: Estimated outage probability.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize an array with negative infinity to store the observed values\n",
    "    observed_values_matrix = np.full((true_values.shape[0], total_ports), -np.inf, dtype=np.float64)\n",
    "\n",
    "    # Assign the true values of the observed ports (channels) to the matrix\n",
    "    observed_values_matrix[:, observed_indices] = true_values[:, observed_indices]\n",
    "\n",
    "    # Find the index of the highest predicted value for each sample\n",
    "    best_predicted_indices = np.argmax(predicted_values, axis=1)\n",
    "\n",
    "    # Initialize an array with negative infinity to store the predicted values\n",
    "    predicted_values_matrix = np.full((true_values.shape[0], total_ports), -np.inf, dtype=np.float64)\n",
    "\n",
    "    # Assign the true value corresponding to the predicted best port\n",
    "    predicted_values_matrix[np.arange(len(best_predicted_indices)), best_predicted_indices] = true_values[\n",
    "        np.arange(len(best_predicted_indices)), best_predicted_indices\n",
    "    ]\n",
    "\n",
    "    # Take the element-wise maximum between the observed and predicted value matrices\n",
    "    best_value_matrix = np.maximum(observed_values_matrix, predicted_values_matrix)\n",
    "\n",
    "    # print(\"Shape of Best Value Matrix:\", best_value_matrix.shape)\n",
    "\n",
    "    # Find the index of the best predicted or observed port (channel) for each sample\n",
    "    best_predicted_or_observed_ports = np.argmax(best_value_matrix, axis=1)\n",
    "\n",
    "    # print(\"Shape of Best Predicted/Observed Ports:\", best_predicted_or_observed_ports.shape)\n",
    "    # print(\"Number of Selected Ports:\", len(best_predicted_or_observed_ports))\n",
    "\n",
    "    # Retrieve the actual values corresponding to the best selected ports\n",
    "    selected_values = best_value_matrix[np.arange(len(true_values)), best_predicted_or_observed_ports]\n",
    "\n",
    "    # print(\"Shape of Selected Values:\", selected_values.shape)\n",
    "\n",
    "    # Determine which selected values are above the given threshold\n",
    "    above_threshold = selected_values > (threshold / snr_linear)\n",
    "\n",
    "    # print(\"Shape of Above Threshold Array:\", above_threshold.shape)\n",
    "\n",
    "    # Compute the outage probability: probability that the selected value is below the threshold\n",
    "    outage_probability = 1.0 - (np.sum(above_threshold) / len(true_values))\n",
    "\n",
    "    return outage_probability\n",
    "\n",
    "\n",
    "def getObservedOP(\n",
    "    observed_indices: np.ndarray, true_values: np.ndarray, threshold: float, snr_linear: float\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Outage probability when you only observe a subset of ports.\n",
    "\n",
    "    For each sample, picks the best SINR among observed ports,\n",
    "    then computes OP = 1 - P(best_obs > threshold/snr_linear).\n",
    "    \"\"\"\n",
    "    # extract only observed-port SINRs\n",
    "    observed_sinr = true_values[:, observed_indices]\n",
    "    # best per sample\n",
    "    best_obs = np.max(observed_sinr, axis=1)\n",
    "    # fraction above threshold\n",
    "    p_above = np.mean(best_obs > (threshold / snr_linear))\n",
    "    return 1.0 - p_above\n",
    "\n",
    "\n",
    "def getIdealOP(true_values: np.ndarray, threshold: float, snr_linear: float) -> float:\n",
    "    \"\"\"\n",
    "    Genie‐aided outage probability knowing all ports.\n",
    "\n",
    "    For each sample, picks the best SINR across all ports,\n",
    "    then computes OP = 1 - P(best_all > threshold/snr_linear).\n",
    "    \"\"\"\n",
    "    best_all = np.max(true_values, axis=1)\n",
    "    p_above = np.mean(best_all > (threshold / snr_linear))\n",
    "    return 1.0 - p_above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAIN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\n",
    "    kappa0_mu1_m0_test,\n",
    "    kappa0_mu1_m2_test,\n",
    "    kappa0_mu1_m50_test,\n",
    "    kappa0_mu2_m50_test,\n",
    "    kappa0_mu5_m50_test,\n",
    "    kappa5_mu1_m0_test,\n",
    "    kappa5_mu1_m2_test,\n",
    "    kappa5_mu1_m50_test,\n",
    "    kappa5_mu2_m0_test,\n",
    "    kappa5_mu2_m2_test,\n",
    "    kappa5_mu2_m50_test,\n",
    "    kappa5_mu5_m0_test,\n",
    "    kappa5_mu5_m2_test,\n",
    "    kappa5_mu5_m50_test,\n",
    "]\n",
    "\n",
    "dataset_names: list[str] = [\n",
    "    \"kappa0_mu1_m0_test\",\n",
    "    \"kappa0_mu1_m2_test\",\n",
    "    \"kappa0_mu1_m50_test\",\n",
    "    \"kappa0_mu2_m50_test\",\n",
    "    \"kappa0_mu5_m50_test\",\n",
    "    \"kappa5_mu1_m0_test\",\n",
    "    \"kappa5_mu1_m2_test\",\n",
    "    \"kappa5_mu1_m50_test\",\n",
    "    \"kappa5_mu2_m0_test\",\n",
    "    \"kappa5_mu2_m2_test\",\n",
    "    \"kappa5_mu2_m50_test\",\n",
    "    \"kappa5_mu5_m0_test\",\n",
    "    \"kappa5_mu5_m2_test\",\n",
    "    \"kappa5_mu5_m50_test\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precompute ideal OP once per dataset\n",
    "ideal_ops_global = [\n",
    "    getIdealOP(data, THRESHOLD, SNR_LINEAR)\n",
    "    for data in datasets\n",
    "]\n",
    "\n",
    "for n_ports, model_path, batch_size, scaler in zip(observed_ports_list, model_paths, batch_sizes, scalers):\n",
    "    # create and/or clear subfolder\n",
    "    sub_dir = os.path.join(RUN_DIR, f\"op_{n_ports}_observed_ports\")\n",
    "    os.makedirs(sub_dir, exist_ok=True)\n",
    "\n",
    "    # load the single model for this n_ports\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "    # fit scaler on training split observed at n_ports\n",
    "    observed_ports, _ = get_observed_ports(dataset, n_ports, TOTAL_NUM_PORTS)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        observed_ports, dataset, test_size=0.2, random_state=0, shuffle=True\n",
    "    )\n",
    "    scaler.fit(X_train)\n",
    "\n",
    "    test_losses = []\n",
    "    ops = []\n",
    "    obs_ops = []\n",
    "\n",
    "    # evaluate on each test subset\n",
    "    for data, name in zip(datasets, dataset_names):\n",
    "        X_test, idxs = get_observed_ports(data, n_ports, TOTAL_NUM_PORTS)\n",
    "        X_test = scaler.transform(X_test).reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "        loss = model.evaluate(X_test, data, batch_size=batch_size, verbose=1)\n",
    "        test_losses.append(loss)\n",
    "\n",
    "        y_pred = model.predict(X_test, verbose=1)\n",
    "        op = getOP(idxs, y_pred, data, THRESHOLD, SNR_LINEAR, TOTAL_NUM_PORTS)\n",
    "        ops.append(op)\n",
    "        \n",
    "        # compute observed-only OP\n",
    "        obs_op = getObservedOP(idxs, data, THRESHOLD, SNR_LINEAR)\n",
    "        obs_ops.append(obs_op)\n",
    "\n",
    "    # print a concise summary\n",
    "    print(f\"\\n=== {n_ports} observed ports ===\")\n",
    "    for name, loss, op, obs_op, ideal_op in zip(\n",
    "        dataset_names, test_losses, ops, obs_ops, ideal_ops_global\n",
    "    ):\n",
    "        print(f\"{name}: Loss={loss:.6f}, OP={op:.6f}, ObsOP={obs_op:.6f}\")\n",
    "\n",
    "    # save results to file\n",
    "    results = {f\"{n}_loss\": l for n, l in zip(dataset_names, test_losses)}\n",
    "    results.update({f\"{n}_op\": o for n, o in zip(dataset_names, ops)})\n",
    "    results.update({f\"{n}_obsOP\": o for n, o in zip(dataset_names, obs_ops)})\n",
    "\n",
    "    out_file = os.path.join(sub_dir, f\"results_{n_ports}_ports.txt\")\n",
    "    troo.save_trial_params_to_file(filepath=out_file, params={}, **results)\n",
    "    \n",
    "# 3. Global ideal-OP section (once per dataset)\n",
    "print(\"\\n=== Ideal Outage Probability (genie-aided) per dataset ===\")\n",
    "for name, ideal_op in zip(dataset_names, ideal_ops_global):\n",
    "    print(f\"{name}: IdealOP={ideal_op:.6f}\")\n",
    "\n",
    "# (Optional) save to a dedicated file\n",
    "ideal_results = {f\"{n}_idealOP\": o for n, o in zip(dataset_names, ideal_ops_global)}\n",
    "ideal_file = os.path.join(RUN_DIR, \"ideal_ops_global.txt\")\n",
    "troo.save_trial_params_to_file(filepath=ideal_file, params={}, **ideal_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-optuna",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
