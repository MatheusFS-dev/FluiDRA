{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NAS - Optuna\n",
    "\n",
    "- **Authored by:** Matheus Ferreira Silva \n",
    "- **GitHub:**: https://github.com/MatheusFS-dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Async CUDA allocator\n",
    "os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'\n",
    "\n",
    "# If cuDNN autotune fails, fall back to a safe (but slower) algorithm.\n",
    "os.environ[\"XLA_FLAGS\"] = \"--xla_gpu_strict_conv_algorithm_picker=false\"\n",
    "\n",
    "# Allow TensorFlow to allocate GPU memory as needed\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from _imports import * # Centralized file containing all imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. GPU Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify GPU to use (e.g., GPU 0)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "troo.get_gpu_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Run Parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOTAL_NUM_PORTS = 100\n",
    "\n",
    "observed_ports_list = [3, 4, 5, 6, 7, 10, 15]\n",
    "batch_sizes = [64, 256, 64, 256, 256, 256, 128]\n",
    "\n",
    "model_paths = [\n",
    "    \"./results/models/lstm/optuna_study_3_ports/models/trial_107.keras\",\n",
    "    \"./results/models/lstm/optuna_study_4_ports/models/trial_200.keras\",\n",
    "    \"./results/models/lstm/optuna_study_5_ports/models/trial_94.keras\",\n",
    "    \"./results/models/lstm/optuna_study_6_ports/models/trial_121.keras\",\n",
    "    \"./results/models/lstm/optuna_study_7_ports/models/trial_178.keras\",\n",
    "    \"./results/models/lstm/optuna_study_10_ports/models/trial_199.keras\",\n",
    "    \"./results/models/lstm/optuna_study_15_ports/models/trial_120.keras\",\n",
    "]\n",
    "\n",
    "scalers = [\n",
    "    StandardScaler(),\n",
    "    StandardScaler(),\n",
    "    StandardScaler(),\n",
    "    StandardScaler(),\n",
    "    StandardScaler(),\n",
    "    StandardScaler(),\n",
    "    StandardScaler(),\n",
    "]\n",
    "\n",
    "THRESHOLD = 0.95\n",
    "SNR_LINEAR = 1.25\n",
    "\n",
    "mixed_precision.set_global_policy(\"mixed_float16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_DIR = troo.create_run_directory(prefix=\"lstm_op_\")\n",
    "print(f\"Run directory: {RUN_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------- Load the dataset in matlab format -------------------- #\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "kappa0_mu1_m0 = scipy.io.loadmat(\"./data/w1_u1_n100/SNR_events_W1.0_U1_N100_kappa1.0e-16_mu1.0_m0.0.mat\")[\"SNR_events\"]\n",
    "kappa0_mu1_m2 = scipy.io.loadmat(\"./data/w1_u1_n100/SNR_events_W1.0_U1_N100_kappa1.0e-16_mu1.0_m2.0.mat\")[\"SNR_events\"]\n",
    "kappa0_mu1_m50 = scipy.io.loadmat(\"./data/w1_u1_n100/SNR_events_W1.0_U1_N100_kappa1.0e-16_mu1.0_m50.0.mat\")[\"SNR_events\"]\n",
    "kappa0_mu2_m50 = scipy.io.loadmat(\"./data/w1_u1_n100/SNR_events_W1.0_U1_N100_kappa1.0e-16_mu2.0_m50.0.mat\")[\"SNR_events\"]\n",
    "kappa0_mu5_m50 = scipy.io.loadmat(\"./data/w1_u1_n100/SNR_events_W1.0_U1_N100_kappa1.0e-16_mu5.0_m50.0.mat\")[\"SNR_events\"]\n",
    "kappa5_mu1_m0 = scipy.io.loadmat(\"./data/w1_u1_n100/SNR_events_W1.0_U1_N100_kappa5.0e+00_mu1.0_m0.0.mat\")[\"SNR_events\"]\n",
    "kappa5_mu1_m2 = scipy.io.loadmat(\"./data/w1_u1_n100/SNR_events_W1.0_U1_N100_kappa5.0e+00_mu1.0_m2.0.mat\")[\"SNR_events\"]\n",
    "kappa5_mu1_m50 = scipy.io.loadmat(\"./data/w1_u1_n100/SNR_events_W1.0_U1_N100_kappa5.0e+00_mu1.0_m50.0.mat\")[\"SNR_events\"]\n",
    "kappa5_mu2_m0 = scipy.io.loadmat(\"./data/w1_u1_n100/SNR_events_W1.0_U1_N100_kappa5.0e+00_mu2.0_m0.0.mat\")[\"SNR_events\"]\n",
    "kappa5_mu2_m2 = scipy.io.loadmat(\"./data/w1_u1_n100/SNR_events_W1.0_U1_N100_kappa5.0e+00_mu2.0_m2.0.mat\")[\"SNR_events\"]\n",
    "kappa5_mu2_m50 = scipy.io.loadmat(\"./data/w1_u1_n100/SNR_events_W1.0_U1_N100_kappa5.0e+00_mu2.0_m50.0.mat\")[\"SNR_events\"]\n",
    "kappa5_mu5_m0 = scipy.io.loadmat(\"./data/w1_u1_n100/SNR_events_W1.0_U1_N100_kappa5.0e+00_mu5.0_m0.0.mat\")[\"SNR_events\"]\n",
    "kappa5_mu5_m2 = scipy.io.loadmat(\"./data/w1_u1_n100/SNR_events_W1.0_U1_N100_kappa5.0e+00_mu5.0_m2.0.mat\")[\"SNR_events\"]\n",
    "kappa5_mu5_m50 = scipy.io.loadmat(\"./data/w1_u1_n100/SNR_events_W1.0_U1_N100_kappa5.0e+00_mu5.0_m50.0.mat\")[\"SNR_events\"]\n",
    "\n",
    "# ————————————— Split the data into 10% training and 90% testing ————————————— #\n",
    "\n",
    "# kappa0_mu1_m0\n",
    "perm = rng.permutation(kappa0_mu1_m0.shape[0])\n",
    "n_test = int(0.9*kappa0_mu1_m0.shape[0])\n",
    "kappa0_mu1_m0_test = kappa0_mu1_m0[perm[:n_test]]\n",
    "kappa0_mu1_m0 = kappa0_mu1_m0[perm[n_test:]]\n",
    "\n",
    "# kappa0_mu1_m2\n",
    "perm = rng.permutation(kappa0_mu1_m2.shape[0])\n",
    "n_test = int(0.9*kappa0_mu1_m2.shape[0])\n",
    "kappa0_mu1_m2_test = kappa0_mu1_m2[perm[:n_test]]\n",
    "kappa0_mu1_m2 = kappa0_mu1_m2[perm[n_test:]]\n",
    "\n",
    "# kappa0_mu1_m50\n",
    "perm = rng.permutation(kappa0_mu1_m50.shape[0])\n",
    "n_test = int(0.9*kappa0_mu1_m50.shape[0])\n",
    "kappa0_mu1_m50_test = kappa0_mu1_m50[perm[:n_test]]\n",
    "kappa0_mu1_m50 = kappa0_mu1_m50[perm[n_test:]]\n",
    "\n",
    "# kappa0_mu2_m50\n",
    "perm = rng.permutation(kappa0_mu2_m50.shape[0])\n",
    "n_test = int(0.9*kappa0_mu2_m50.shape[0])\n",
    "kappa0_mu2_m50_test = kappa0_mu2_m50[perm[:n_test]]\n",
    "kappa0_mu2_m50 = kappa0_mu2_m50[perm[n_test:]]\n",
    "\n",
    "# kappa0_mu5_m50\n",
    "perm = rng.permutation(kappa0_mu5_m50.shape[0])\n",
    "n_test = int(0.9*kappa0_mu5_m50.shape[0])\n",
    "kappa0_mu5_m50_test = kappa0_mu5_m50[perm[:n_test]]\n",
    "kappa0_mu5_m50 = kappa0_mu5_m50[perm[n_test:]]\n",
    "\n",
    "# kappa5_mu1_m0\n",
    "perm = rng.permutation(kappa5_mu1_m0.shape[0])\n",
    "n_test = int(0.9*kappa5_mu1_m0.shape[0])\n",
    "kappa5_mu1_m0_test = kappa5_mu1_m0[perm[:n_test]]\n",
    "kappa5_mu1_m0 = kappa5_mu1_m0[perm[n_test:]]\n",
    "\n",
    "# kappa5_mu1_m2\n",
    "perm = rng.permutation(kappa5_mu1_m2.shape[0])\n",
    "n_test = int(0.9*kappa5_mu1_m2.shape[0])\n",
    "kappa5_mu1_m2_test = kappa5_mu1_m2[perm[:n_test]]\n",
    "kappa5_mu1_m2 = kappa5_mu1_m2[perm[n_test:]]\n",
    "\n",
    "# kappa5_mu1_m50\n",
    "perm = rng.permutation(kappa5_mu1_m50.shape[0])\n",
    "n_test = int(0.9*kappa5_mu1_m50.shape[0])\n",
    "kappa5_mu1_m50_test = kappa5_mu1_m50[perm[:n_test]]\n",
    "kappa5_mu1_m50 = kappa5_mu1_m50[perm[n_test:]]\n",
    "\n",
    "# kappa5_mu2_m0\n",
    "perm = rng.permutation(kappa5_mu2_m0.shape[0])\n",
    "n_test = int(0.9*kappa5_mu2_m0.shape[0])\n",
    "kappa5_mu2_m0_test = kappa5_mu2_m0[perm[:n_test]]\n",
    "kappa5_mu2_m0 = kappa5_mu2_m0[perm[n_test:]]\n",
    "\n",
    "# kappa5_mu2_m2\n",
    "perm = rng.permutation(kappa5_mu2_m2.shape[0])\n",
    "n_test = int(0.9*kappa5_mu2_m2.shape[0])\n",
    "kappa5_mu2_m2_test = kappa5_mu2_m2[perm[:n_test]]\n",
    "kappa5_mu2_m2 = kappa5_mu2_m2[perm[n_test:]]\n",
    "\n",
    "# kappa5_mu2_m50\n",
    "perm = rng.permutation(kappa5_mu2_m50.shape[0])\n",
    "n_test = int(0.9*kappa5_mu2_m50.shape[0])\n",
    "kappa5_mu2_m50_test = kappa5_mu2_m50[perm[:n_test]]\n",
    "kappa5_mu2_m50 = kappa5_mu2_m50[perm[n_test:]]\n",
    "\n",
    "# kappa5_mu5_m0\n",
    "perm = rng.permutation(kappa5_mu5_m0.shape[0])\n",
    "n_test = int(0.9*kappa5_mu5_m0.shape[0])\n",
    "kappa5_mu5_m0_test = kappa5_mu5_m0[perm[:n_test]]\n",
    "kappa5_mu5_m0 = kappa5_mu5_m0[perm[n_test:]]\n",
    "\n",
    "# kappa5_mu5_m2\n",
    "perm = rng.permutation(kappa5_mu5_m2.shape[0])\n",
    "n_test = int(0.9*kappa5_mu5_m2.shape[0])\n",
    "kappa5_mu5_m2_test = kappa5_mu5_m2[perm[:n_test]]\n",
    "kappa5_mu5_m2 = kappa5_mu5_m2[perm[n_test:]]\n",
    "\n",
    "# kappa5_mu5_m50\n",
    "perm = rng.permutation(kappa5_mu5_m50.shape[0])\n",
    "n_test = int(0.9*kappa5_mu5_m50.shape[0])\n",
    "kappa5_mu5_m50_test = kappa5_mu5_m50[perm[:n_test]]\n",
    "kappa5_mu5_m50 = kappa5_mu5_m50[perm[n_test:]]\n",
    "\n",
    "# ————————————— Concatenate all training subsamples along axis=0 ————————————— #\n",
    "dataset = np.concatenate(\n",
    "    [\n",
    "        kappa0_mu1_m0,\n",
    "        kappa0_mu1_m2,\n",
    "        kappa0_mu1_m50,\n",
    "        kappa0_mu2_m50,\n",
    "        kappa0_mu5_m50,\n",
    "        kappa5_mu1_m0,\n",
    "        kappa5_mu1_m2,\n",
    "        kappa5_mu1_m50,\n",
    "        kappa5_mu2_m0,\n",
    "        kappa5_mu2_m2,\n",
    "        kappa5_mu2_m50,\n",
    "        kappa5_mu5_m0,\n",
    "        kappa5_mu5_m2,\n",
    "        kappa5_mu5_m50,\n",
    "    ],\n",
    "    axis=0,\n",
    ")\n",
    "\n",
    "print(f\"Original dataset shape: {dataset.shape}\")\n",
    "\n",
    "# Subsample data\n",
    "# dataset = dataset[: int(0.01 * dataset.shape[0]), :]\n",
    "\n",
    "print(f\"Shape of the data after configuration: {dataset.shape}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Getters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6. Implementation getters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_observed_ports(sinr_data, num_observed_ports, total_ports):\n",
    "    \"\"\"\n",
    "    Extracts SINR values for the specified number of observed ports.\n",
    "\n",
    "    The function selects a subset of SINR data by identifying equally spaced ports based on the\n",
    "    number of observed ports specified. It returns the SINR values for these observed ports and\n",
    "    their corresponding indices.\n",
    "\n",
    "    Args:\n",
    "        sinr_data (numpy.ndarray): A 2D array where each row represents an observation and each column\n",
    "                                   represents a port with its corresponding SINR values.\n",
    "        num_observed_ports (int): The number of observed ports to select from the SINR data.\n",
    "        total_ports (int): The total number of ports in the SINR data.\n",
    "\n",
    "    Returns:\n",
    "        observed_sinr (numpy.ndarray): A 2D array containing the SINR values for the observed ports.\n",
    "        observed_indices (numpy.ndarray): A 1D array of the indices corresponding to the observed ports.\n",
    "    \"\"\"\n",
    "    observed_indices = np.linspace(0, total_ports - 1, num_observed_ports, dtype=int)\n",
    "    observed_sinr = sinr_data[:, observed_indices]\n",
    "\n",
    "    return observed_sinr, observed_indices\n",
    "\n",
    "\n",
    "def getOP(\n",
    "    observed_indices: np.ndarray,\n",
    "    predicted_values: np.ndarray,\n",
    "    true_values: np.ndarray,\n",
    "    threshold: float,\n",
    "    snr_linear: float,\n",
    "    total_ports: int,\n",
    ") -> float:\n",
    "    \"\"\"Estimate the outage probability for regression models.\n",
    "\n",
    "    This function compares the predicted and observed signal values at different\n",
    "    channels (ports) and determines whether the chosen signal is above a given threshold.\n",
    "    The outage probability is then computed as the proportion of times the signal falls\n",
    "    below this threshold.\n",
    "\n",
    "    Args:\n",
    "        observed_indices (np.ndarray): Indices of the observed ports (channels).\n",
    "        predicted_values (np.ndarray): Matrix of predicted values for each sample.\n",
    "        true_values (np.ndarray): Ground-truth values for each port.\n",
    "        threshold (float): Threshold value for determining outage.\n",
    "        snr_linear (float): Signal-to-noise ratio in linear scale.\n",
    "\n",
    "    Returns:\n",
    "        float: Estimated outage probability.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize an array with negative infinity to store the observed values\n",
    "    observed_values_matrix = np.full((true_values.shape[0], total_ports), -np.inf, dtype=np.float64)\n",
    "\n",
    "    # Assign the true values of the observed ports (channels) to the matrix\n",
    "    observed_values_matrix[:, observed_indices] = true_values[:, observed_indices]\n",
    "\n",
    "    # Find the index of the highest predicted value for each sample\n",
    "    best_predicted_indices = np.argmax(predicted_values, axis=1)\n",
    "\n",
    "    # Initialize an array with negative infinity to store the predicted values\n",
    "    predicted_values_matrix = np.full((true_values.shape[0], total_ports), -np.inf, dtype=np.float64)\n",
    "\n",
    "    # Assign the true value corresponding to the predicted best port\n",
    "    predicted_values_matrix[np.arange(len(best_predicted_indices)), best_predicted_indices] = true_values[\n",
    "        np.arange(len(best_predicted_indices)), best_predicted_indices\n",
    "    ]\n",
    "\n",
    "    # Take the element-wise maximum between the observed and predicted value matrices\n",
    "    best_value_matrix = np.maximum(observed_values_matrix, predicted_values_matrix)\n",
    "\n",
    "    # print(\"Shape of Best Value Matrix:\", best_value_matrix.shape)\n",
    "\n",
    "    # Find the index of the best predicted or observed port (channel) for each sample\n",
    "    best_predicted_or_observed_ports = np.argmax(best_value_matrix, axis=1)\n",
    "\n",
    "    # print(\"Shape of Best Predicted/Observed Ports:\", best_predicted_or_observed_ports.shape)\n",
    "    # print(\"Number of Selected Ports:\", len(best_predicted_or_observed_ports))\n",
    "\n",
    "    # Retrieve the actual values corresponding to the best selected ports\n",
    "    selected_values = best_value_matrix[np.arange(len(true_values)), best_predicted_or_observed_ports]\n",
    "\n",
    "    # print(\"Shape of Selected Values:\", selected_values.shape)\n",
    "\n",
    "    # Determine which selected values are above the given threshold\n",
    "    above_threshold = selected_values > (threshold / snr_linear)\n",
    "\n",
    "    # print(\"Shape of Above Threshold Array:\", above_threshold.shape)\n",
    "\n",
    "    # Compute the outage probability: probability that the selected value is below the threshold\n",
    "    outage_probability = 1.0 - (np.sum(above_threshold) / len(true_values))\n",
    "\n",
    "    return outage_probability\n",
    "\n",
    "\n",
    "def getObservedOP(\n",
    "    observed_indices: np.ndarray, true_values: np.ndarray, threshold: float, snr_linear: float\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Outage probability when you only observe a subset of ports.\n",
    "\n",
    "    For each sample, picks the best SINR among observed ports,\n",
    "    then computes OP = 1 - P(best_obs > threshold/snr_linear).\n",
    "    \"\"\"\n",
    "    # extract only observed-port SINRs\n",
    "    observed_sinr = true_values[:, observed_indices]\n",
    "    # best per sample\n",
    "    best_obs = np.max(observed_sinr, axis=1)\n",
    "    # fraction above threshold\n",
    "    p_above = np.mean(best_obs > (threshold / snr_linear))\n",
    "    return 1.0 - p_above\n",
    "\n",
    "\n",
    "def getIdealOP(true_values: np.ndarray, threshold: float, snr_linear: float) -> float:\n",
    "    \"\"\"\n",
    "    Genie‐aided outage probability knowing all ports.\n",
    "\n",
    "    For each sample, picks the best SINR across all ports,\n",
    "    then computes OP = 1 - P(best_all > threshold/snr_linear).\n",
    "    \"\"\"\n",
    "    best_all = np.max(true_values, axis=1)\n",
    "    p_above = np.mean(best_all > (threshold / snr_linear))\n",
    "    return 1.0 - p_above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAIN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\n",
    "    kappa0_mu1_m0_test,\n",
    "    kappa0_mu1_m2_test,\n",
    "    kappa0_mu1_m50_test,\n",
    "    kappa0_mu2_m50_test,\n",
    "    kappa0_mu5_m50_test,\n",
    "    kappa5_mu1_m0_test,\n",
    "    kappa5_mu1_m2_test,\n",
    "    kappa5_mu1_m50_test,\n",
    "    kappa5_mu2_m0_test,\n",
    "    kappa5_mu2_m2_test,\n",
    "    kappa5_mu2_m50_test,\n",
    "    kappa5_mu5_m0_test,\n",
    "    kappa5_mu5_m2_test,\n",
    "    kappa5_mu5_m50_test,\n",
    "]\n",
    "\n",
    "dataset_names: list[str] = [\n",
    "    \"kappa0_mu1_m0_test\",\n",
    "    \"kappa0_mu1_m2_test\",\n",
    "    \"kappa0_mu1_m50_test\",\n",
    "    \"kappa0_mu2_m50_test\",\n",
    "    \"kappa0_mu5_m50_test\",\n",
    "    \"kappa5_mu1_m0_test\",\n",
    "    \"kappa5_mu1_m2_test\",\n",
    "    \"kappa5_mu1_m50_test\",\n",
    "    \"kappa5_mu2_m0_test\",\n",
    "    \"kappa5_mu2_m2_test\",\n",
    "    \"kappa5_mu2_m50_test\",\n",
    "    \"kappa5_mu5_m0_test\",\n",
    "    \"kappa5_mu5_m2_test\",\n",
    "    \"kappa5_mu5_m50_test\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 647us/step\n",
      "\u001b[1m3516/3516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 652us/step - loss: 0.0674\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 710us/step\n",
      "\u001b[1m3516/3516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 727us/step - loss: 0.0676\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 669us/step\n",
      "\u001b[1m3516/3516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 791us/step - loss: 0.0461\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 745us/step\n",
      "\u001b[1m3516/3516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 758us/step - loss: 0.0332\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 708us/step\n",
      "\u001b[1m3516/3516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 724us/step - loss: 11.2353\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 709us/step\n",
      "\u001b[1m3516/3516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 784us/step - loss: 0.0526\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 753us/step\n",
      "\u001b[1m3516/3516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 724us/step - loss: 0.0385\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 782us/step\n",
      "\u001b[1m3516/3516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 824us/step - loss: 10.0971\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 729us/step\n",
      "\u001b[1m3516/3516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 659us/step - loss: 0.0462\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 757us/step\n",
      "\u001b[1m3516/3516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 723us/step - loss: 0.0318\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 677us/step\n",
      "\u001b[1m3516/3516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 683us/step - loss: 10.5021\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 677us/step\n",
      "\u001b[1m3516/3516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 661us/step - loss: 0.0422\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 688us/step\n",
      "\u001b[1m3516/3516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 664us/step - loss: 0.0280\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 760us/step\n",
      "\n",
      "=== 7 observed ports ===\n",
      "kappa0_mu1_m0_test: Loss=0.067848, OP=0.077243, ObsOP=0.080878\n",
      "kappa0_mu1_m2_test: Loss=0.067791, OP=0.077837, ObsOP=0.081499\n",
      "kappa0_mu1_m50_test: Loss=0.067562, OP=0.077897, ObsOP=0.081584\n",
      "kappa0_mu2_m50_test: Loss=0.046127, OP=0.022004, ObsOP=0.023697\n",
      "kappa0_mu5_m50_test: Loss=0.033262, OP=0.001449, ObsOP=0.001624\n",
      "kappa5_mu1_m0_test: Loss=11.592216, OP=0.913968, ObsOP=0.919340\n",
      "kappa5_mu1_m2_test: Loss=0.052535, OP=0.041530, ObsOP=0.044019\n",
      "kappa5_mu1_m50_test: Loss=0.038458, OP=0.009430, ObsOP=0.010308\n",
      "kappa5_mu2_m0_test: Loss=10.847305, OP=0.950733, ObsOP=0.953604\n",
      "kappa5_mu2_m2_test: Loss=0.046172, OP=0.021919, ObsOP=0.023709\n",
      "kappa5_mu2_m50_test: Loss=0.031843, OP=0.001053, ObsOP=0.001189\n",
      "kappa5_mu5_m0_test: Loss=10.730231, OP=0.969776, ObsOP=0.970341\n",
      "kappa5_mu5_m2_test: Loss=0.042209, OP=0.011579, ObsOP=0.012718\n",
      "kappa5_mu5_m50_test: Loss=0.028013, OP=0.000020, ObsOP=0.000023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matheus/anaconda3/envs/tf-optuna/lib/python3.11/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'loss_scale_optimizer', because it has 16 variables whereas the saved optimizer has 12 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/home/matheus/anaconda3/envs/tf-optuna/lib/python3.11/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adamw', because it has 12 variables whereas the saved optimizer has 0 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3516/3516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 813us/step - loss: 1.5651e-04\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 669us/step\n",
      "\u001b[1m3516/3516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 724us/step - loss: 1.5536e-04\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 628us/step\n",
      "\u001b[1m3516/3516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 615us/step - loss: 1.5290e-04\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 577us/step\n",
      "\u001b[1m3516/3516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 615us/step - loss: 9.7442e-05\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 604us/step\n",
      "\u001b[1m3516/3516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 512us/step - loss: 7.9985e-05\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 484us/step\n",
      "\u001b[1m3516/3516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 751us/step - loss: 0.0543\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 721us/step\n",
      "\u001b[1m3516/3516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 654us/step - loss: 1.1009e-04\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 600us/step\n",
      "\u001b[1m3516/3516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 648us/step - loss: 8.4931e-05\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 624us/step\n",
      "\u001b[1m3516/3516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 725us/step - loss: 0.0290\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 664us/step\n",
      "\u001b[1m3516/3516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 641us/step - loss: 9.6944e-05\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 616us/step\n",
      "\u001b[1m3516/3516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 638us/step - loss: 7.8472e-05\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 634us/step\n",
      "\u001b[1m3516/3516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 672us/step - loss: 0.0309\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 622us/step\n",
      "\u001b[1m3516/3516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 738us/step - loss: 9.0842e-05\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 717us/step\n",
      "\u001b[1m3516/3516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 800us/step - loss: 7.5260e-05\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 646us/step\n",
      "\n",
      "=== 10 observed ports ===\n",
      "kappa0_mu1_m0_test: Loss=0.000155, OP=0.074739, ObsOP=0.077329\n",
      "kappa0_mu1_m2_test: Loss=0.000156, OP=0.075272, ObsOP=0.077912\n",
      "kappa0_mu1_m50_test: Loss=0.000153, OP=0.075237, ObsOP=0.077930\n",
      "kappa0_mu2_m50_test: Loss=0.000097, OP=0.020520, ObsOP=0.021792\n",
      "kappa0_mu5_m50_test: Loss=0.000080, OP=0.001212, ObsOP=0.001369\n",
      "kappa5_mu1_m0_test: Loss=0.060758, OP=0.911203, ObsOP=0.914979\n",
      "kappa5_mu1_m2_test: Loss=0.000109, OP=0.039544, ObsOP=0.041417\n",
      "kappa5_mu1_m50_test: Loss=0.000085, OP=0.008591, ObsOP=0.009273\n",
      "kappa5_mu2_m0_test: Loss=0.047326, OP=0.949161, ObsOP=0.951312\n",
      "kappa5_mu2_m2_test: Loss=0.000097, OP=0.020473, ObsOP=0.021796\n",
      "kappa5_mu2_m50_test: Loss=0.000078, OP=0.000893, ObsOP=0.001003\n",
      "kappa5_mu5_m0_test: Loss=0.031362, OP=0.969429, ObsOP=0.969844\n",
      "kappa5_mu5_m2_test: Loss=0.000091, OP=0.010458, ObsOP=0.011313\n",
      "kappa5_mu5_m50_test: Loss=0.000075, OP=0.000013, ObsOP=0.000018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matheus/anaconda3/envs/tf-optuna/lib/python3.11/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'loss_scale_optimizer', because it has 16 variables whereas the saved optimizer has 12 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/home/matheus/anaconda3/envs/tf-optuna/lib/python3.11/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adamw', because it has 12 variables whereas the saved optimizer has 0 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7032/7032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 751us/step - loss: 1.9340e-04\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 601us/step\n",
      "\u001b[1m7032/7032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 588us/step - loss: 1.8969e-04\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 593us/step\n",
      "\u001b[1m7032/7032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 585us/step - loss: 1.8675e-04\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 597us/step\n",
      "\u001b[1m7032/7032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 677us/step - loss: 9.3888e-05\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 728us/step\n",
      "\u001b[1m7032/7032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 697us/step - loss: 7.1661e-05\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 704us/step\n",
      "\u001b[1m7032/7032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 667us/step - loss: 0.0318\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 718us/step\n",
      "\u001b[1m7032/7032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 617us/step - loss: 1.1151e-04\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 605us/step\n",
      "\u001b[1m7032/7032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 585us/step - loss: 7.7666e-05\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 732us/step\n",
      "\u001b[1m7032/7032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 702us/step - loss: 0.0168\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 712us/step\n",
      "\u001b[1m7032/7032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 738us/step - loss: 9.4161e-05\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 619us/step\n",
      "\u001b[1m7032/7032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 614us/step - loss: 6.9963e-05\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 617us/step\n",
      "\u001b[1m7032/7032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 584us/step - loss: 0.0197\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 638us/step\n",
      "\u001b[1m7032/7032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 640us/step - loss: 8.5251e-05\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 632us/step\n",
      "\u001b[1m7032/7032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 621us/step - loss: 6.6701e-05\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 622us/step\n",
      "\n",
      "=== 15 observed ports ===\n",
      "kappa0_mu1_m0_test: Loss=0.000189, OP=0.074759, ObsOP=0.075734\n",
      "kappa0_mu1_m2_test: Loss=0.000191, OP=0.075289, ObsOP=0.076290\n",
      "kappa0_mu1_m50_test: Loss=0.000187, OP=0.075263, ObsOP=0.076287\n",
      "kappa0_mu2_m50_test: Loss=0.000093, OP=0.020529, ObsOP=0.021000\n",
      "kappa0_mu5_m50_test: Loss=0.000072, OP=0.001214, ObsOP=0.001277\n",
      "kappa5_mu1_m0_test: Loss=0.034120, OP=0.911223, ObsOP=0.912819\n",
      "kappa5_mu1_m2_test: Loss=0.000111, OP=0.039549, ObsOP=0.040286\n",
      "kappa5_mu1_m50_test: Loss=0.000078, OP=0.008602, ObsOP=0.008852\n",
      "kappa5_mu2_m0_test: Loss=0.028258, OP=0.949178, ObsOP=0.950078\n",
      "kappa5_mu2_m2_test: Loss=0.000094, OP=0.020483, ObsOP=0.021006\n",
      "kappa5_mu2_m50_test: Loss=0.000070, OP=0.000894, ObsOP=0.000926\n",
      "kappa5_mu5_m0_test: Loss=0.016286, OP=0.969434, ObsOP=0.969622\n",
      "kappa5_mu5_m2_test: Loss=0.000085, OP=0.010457, ObsOP=0.010792\n",
      "kappa5_mu5_m50_test: Loss=0.000067, OP=0.000013, ObsOP=0.000016\n",
      "\n",
      "=== Ideal Outage Probability (genie-aided) per dataset ===\n",
      "kappa0_mu1_m0_test: IdealOP=0.074659\n",
      "kappa0_mu1_m2_test: IdealOP=0.075188\n",
      "kappa0_mu1_m50_test: IdealOP=0.075157\n",
      "kappa0_mu2_m50_test: IdealOP=0.020477\n",
      "kappa0_mu5_m50_test: IdealOP=0.001201\n",
      "kappa5_mu1_m0_test: IdealOP=0.911136\n",
      "kappa5_mu1_m2_test: IdealOP=0.039483\n",
      "kappa5_mu1_m50_test: IdealOP=0.008571\n",
      "kappa5_mu2_m0_test: IdealOP=0.949119\n",
      "kappa5_mu2_m2_test: IdealOP=0.020428\n",
      "kappa5_mu2_m50_test: IdealOP=0.000891\n",
      "kappa5_mu5_m0_test: IdealOP=0.969417\n",
      "kappa5_mu5_m2_test: IdealOP=0.010421\n",
      "kappa5_mu5_m50_test: IdealOP=0.000013\n"
     ]
    }
   ],
   "source": [
    "# Precompute ideal OP once per dataset\n",
    "ideal_ops_global = [\n",
    "    getIdealOP(data, THRESHOLD, SNR_LINEAR)\n",
    "    for data in datasets\n",
    "]\n",
    "\n",
    "for n_ports, model_path, batch_size, scaler in zip(observed_ports_list, model_paths, batch_sizes, scalers):\n",
    "    # create and/or clear subfolder\n",
    "    sub_dir = os.path.join(RUN_DIR, f\"op_{n_ports}_observed_ports\")\n",
    "    os.makedirs(sub_dir, exist_ok=True)\n",
    "\n",
    "    # load the single model for this n_ports\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "    # fit scaler on training split observed at n_ports\n",
    "    observed_ports, _ = get_observed_ports(dataset, n_ports, TOTAL_NUM_PORTS)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        observed_ports, dataset, test_size=0.2, random_state=0, shuffle=True\n",
    "    )\n",
    "    scaler.fit(X_train)\n",
    "\n",
    "    test_losses = []\n",
    "    ops = []\n",
    "    obs_ops = []\n",
    "\n",
    "    # evaluate on each test subset\n",
    "    for data, name in zip(datasets, dataset_names):\n",
    "        X_test, idxs = get_observed_ports(data, n_ports, TOTAL_NUM_PORTS)\n",
    "        X_test = scaler.transform(X_test).reshape(X_test.shape[0], 1, X_test.shape[1])\n",
    "        loss = model.evaluate(X_test, data, batch_size=batch_size, verbose=1)\n",
    "        test_losses.append(loss)\n",
    "\n",
    "        y_pred = model.predict(X_test, verbose=1)\n",
    "        op = getOP(idxs, y_pred, data, THRESHOLD, SNR_LINEAR, TOTAL_NUM_PORTS)\n",
    "        ops.append(op)\n",
    "\n",
    "        # compute observed-only OP\n",
    "        obs_op = getObservedOP(idxs, data, THRESHOLD, SNR_LINEAR)\n",
    "        obs_ops.append(obs_op)\n",
    "\n",
    "    # print a concise summary\n",
    "    print(f\"\\n=== {n_ports} observed ports ===\")\n",
    "    for name, loss, op, obs_op, ideal_op in zip(\n",
    "        dataset_names, test_losses, ops, obs_ops, ideal_ops_global\n",
    "    ):\n",
    "        print(f\"{name}: Loss={loss:.6f}, OP={op:.6f}, ObsOP={obs_op:.6f}\")\n",
    "\n",
    "    # save results to file\n",
    "    results = {f\"{n}_loss\": l for n, l in zip(dataset_names, test_losses)}\n",
    "    results.update({f\"{n}_op\": o for n, o in zip(dataset_names, ops)})\n",
    "    results.update({f\"{n}_obsOP\": o for n, o in zip(dataset_names, obs_ops)})\n",
    "\n",
    "    out_file = os.path.join(sub_dir, f\"results_{n_ports}_ports.txt\")\n",
    "    troo.save_trial_params_to_file(filepath=out_file, params={}, **results)\n",
    "\n",
    "# 3. Global ideal-OP section (once per dataset)\n",
    "print(\"\\n=== Ideal Outage Probability (genie-aided) per dataset ===\")\n",
    "for name, ideal_op in zip(dataset_names, ideal_ops_global):\n",
    "    print(f\"{name}: IdealOP={ideal_op:.6f}\")\n",
    "\n",
    "# (Optional) save to a dedicated file\n",
    "ideal_results = {f\"{n}_idealOP\": o for n, o in zip(dataset_names, ideal_ops_global)}\n",
    "ideal_file = os.path.join(RUN_DIR, \"ideal_ops_global.txt\")\n",
    "troo.save_trial_params_to_file(filepath=ideal_file, params={}, **ideal_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-optuna",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
