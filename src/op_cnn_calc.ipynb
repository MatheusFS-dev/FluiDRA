{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NAS - Optuna\n",
    "\n",
    "- **Authored by:** Matheus Ferreira Silva \n",
    "- **GitHub:**: https://github.com/MatheusFS-dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Async CUDA allocator\n",
    "os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'\n",
    "\n",
    "# If cuDNN autotune fails, fall back to a safe (but slower) algorithm.\n",
    "os.environ[\"XLA_FLAGS\"] = \"--xla_gpu_strict_conv_algorithm_picker=false\"\n",
    "\n",
    "# Allow TensorFlow to allocate GPU memory as needed\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-18 10:30:56.561074: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-18 10:30:56.574101: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1747575056.586999   20089 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1747575056.590198   20089 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-05-18 10:30:56.604774: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/matheus/anaconda3/envs/tf-optuna/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from _imports import * # Centralized file containing all imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. GPU Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 2.18.0\n",
      "CUDA support detected\n",
      "  CUDA Version: 12.5.1\n",
      "  cuDNN Version: 9\n",
      "\n",
      "GPUs Detected (1): ['/physical_device:GPU:0']\n",
      "Default GPU device: /device:GPU:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-18 10:30:58.668530: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "I0000 00:00:1747575058.668583   20089 gpu_process_state.cc:201] Using CUDA malloc Async allocator for GPU: 0\n",
      "I0000 00:00:1747575058.668842   20089 gpu_device.cc:2022] Created device /device:GPU:0 with 2229 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "# Specify GPU to use (e.g., GPU 0)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "troo.get_gpu_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Run Parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOTAL_NUM_PORTS = 100\n",
    "\n",
    "observed_ports_list = [3, 4, 5, 6, 7, 10, 15]\n",
    "batch_sizes = [64, 64, 128, 64, 64, 256, 128]\n",
    "\n",
    "model_paths = [\n",
    "    \"./results/models/cnn/optuna_study_3_ports/models/trial_134.keras\",\n",
    "    \"./results/models/cnn/optuna_study_4_ports/models/trial_139.keras\",\n",
    "    \"./results/models/cnn/optuna_study_5_ports/models/trial_178.keras\",\n",
    "    \"./results/models/cnn/optuna_study_6_ports/models/trial_79.keras\",\n",
    "    \"./results/models/cnn/optuna_study_7_ports/models/trial_183.keras\",\n",
    "    \"./results/models/cnn/optuna_study_10_ports/models/trial_125.keras\",\n",
    "    \"./results/models/cnn/optuna_study_15_ports/models/trial_183.keras\",\n",
    "]\n",
    "\n",
    "scalers = [\n",
    "    StandardScaler(),\n",
    "    StandardScaler(),\n",
    "    StandardScaler(),\n",
    "    StandardScaler(),\n",
    "    StandardScaler(),\n",
    "    StandardScaler(),\n",
    "    StandardScaler(),\n",
    "]\n",
    "\n",
    "\n",
    "THRESHOLD = 0.95\n",
    "SNR_LINEAR = 1.25\n",
    "\n",
    "mixed_precision.set_global_policy(\"mixed_float16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run directory: runs/cnn_op_1\n"
     ]
    }
   ],
   "source": [
    "RUN_DIR = troo.create_run_directory(prefix=\"cnn_op_\")\n",
    "print(f\"Run directory: {RUN_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape: (1400000, 100)\n",
      "Shape of the data after configuration: (1400000, 100)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --------------------- Load the dataset in matlab format -------------------- #\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "kappa0_mu1_m0 = scipy.io.loadmat(\"./data/w1_u1_n100/SNR_events_W1.0_U1_N100_kappa1.0e-16_mu1.0_m0.0.mat\")[\"SNR_events\"]\n",
    "kappa0_mu1_m2 = scipy.io.loadmat(\"./data/w1_u1_n100/SNR_events_W1.0_U1_N100_kappa1.0e-16_mu1.0_m2.0.mat\")[\"SNR_events\"]\n",
    "kappa0_mu1_m50 = scipy.io.loadmat(\"./data/w1_u1_n100/SNR_events_W1.0_U1_N100_kappa1.0e-16_mu1.0_m50.0.mat\")[\"SNR_events\"]\n",
    "kappa0_mu2_m50 = scipy.io.loadmat(\"./data/w1_u1_n100/SNR_events_W1.0_U1_N100_kappa1.0e-16_mu2.0_m50.0.mat\")[\"SNR_events\"]\n",
    "kappa0_mu5_m50 = scipy.io.loadmat(\"./data/w1_u1_n100/SNR_events_W1.0_U1_N100_kappa1.0e-16_mu5.0_m50.0.mat\")[\"SNR_events\"]\n",
    "kappa5_mu1_m0 = scipy.io.loadmat(\"./data/w1_u1_n100/SNR_events_W1.0_U1_N100_kappa5.0e+00_mu1.0_m0.0.mat\")[\"SNR_events\"]\n",
    "kappa5_mu1_m2 = scipy.io.loadmat(\"./data/w1_u1_n100/SNR_events_W1.0_U1_N100_kappa5.0e+00_mu1.0_m2.0.mat\")[\"SNR_events\"]\n",
    "kappa5_mu1_m50 = scipy.io.loadmat(\"./data/w1_u1_n100/SNR_events_W1.0_U1_N100_kappa5.0e+00_mu1.0_m50.0.mat\")[\"SNR_events\"]\n",
    "kappa5_mu2_m0 = scipy.io.loadmat(\"./data/w1_u1_n100/SNR_events_W1.0_U1_N100_kappa5.0e+00_mu2.0_m0.0.mat\")[\"SNR_events\"]\n",
    "kappa5_mu2_m2 = scipy.io.loadmat(\"./data/w1_u1_n100/SNR_events_W1.0_U1_N100_kappa5.0e+00_mu2.0_m2.0.mat\")[\"SNR_events\"]\n",
    "kappa5_mu2_m50 = scipy.io.loadmat(\"./data/w1_u1_n100/SNR_events_W1.0_U1_N100_kappa5.0e+00_mu2.0_m50.0.mat\")[\"SNR_events\"]\n",
    "kappa5_mu5_m0 = scipy.io.loadmat(\"./data/w1_u1_n100/SNR_events_W1.0_U1_N100_kappa5.0e+00_mu5.0_m0.0.mat\")[\"SNR_events\"]\n",
    "kappa5_mu5_m2 = scipy.io.loadmat(\"./data/w1_u1_n100/SNR_events_W1.0_U1_N100_kappa5.0e+00_mu5.0_m2.0.mat\")[\"SNR_events\"]\n",
    "kappa5_mu5_m50 = scipy.io.loadmat(\"./data/w1_u1_n100/SNR_events_W1.0_U1_N100_kappa5.0e+00_mu5.0_m50.0.mat\")[\"SNR_events\"]\n",
    "\n",
    "# ————————————— Split the data into 10% training and 90% testing ————————————— #\n",
    "\n",
    "# kappa0_mu1_m0\n",
    "perm = rng.permutation(kappa0_mu1_m0.shape[0])\n",
    "n_test = int(0.9*kappa0_mu1_m0.shape[0])\n",
    "kappa0_mu1_m0_test = kappa0_mu1_m0[perm[:n_test]]\n",
    "kappa0_mu1_m0 = kappa0_mu1_m0[perm[n_test:]]\n",
    "\n",
    "# kappa0_mu1_m2\n",
    "perm = rng.permutation(kappa0_mu1_m2.shape[0])\n",
    "n_test = int(0.9*kappa0_mu1_m2.shape[0])\n",
    "kappa0_mu1_m2_test = kappa0_mu1_m2[perm[:n_test]]\n",
    "kappa0_mu1_m2 = kappa0_mu1_m2[perm[n_test:]]\n",
    "\n",
    "# kappa0_mu1_m50\n",
    "perm = rng.permutation(kappa0_mu1_m50.shape[0])\n",
    "n_test = int(0.9*kappa0_mu1_m50.shape[0])\n",
    "kappa0_mu1_m50_test = kappa0_mu1_m50[perm[:n_test]]\n",
    "kappa0_mu1_m50 = kappa0_mu1_m50[perm[n_test:]]\n",
    "\n",
    "# kappa0_mu2_m50\n",
    "perm = rng.permutation(kappa0_mu2_m50.shape[0])\n",
    "n_test = int(0.9*kappa0_mu2_m50.shape[0])\n",
    "kappa0_mu2_m50_test = kappa0_mu2_m50[perm[:n_test]]\n",
    "kappa0_mu2_m50 = kappa0_mu2_m50[perm[n_test:]]\n",
    "\n",
    "# kappa0_mu5_m50\n",
    "perm = rng.permutation(kappa0_mu5_m50.shape[0])\n",
    "n_test = int(0.9*kappa0_mu5_m50.shape[0])\n",
    "kappa0_mu5_m50_test = kappa0_mu5_m50[perm[:n_test]]\n",
    "kappa0_mu5_m50 = kappa0_mu5_m50[perm[n_test:]]\n",
    "\n",
    "# kappa5_mu1_m0\n",
    "perm = rng.permutation(kappa5_mu1_m0.shape[0])\n",
    "n_test = int(0.9*kappa5_mu1_m0.shape[0])\n",
    "kappa5_mu1_m0_test = kappa5_mu1_m0[perm[:n_test]]\n",
    "kappa5_mu1_m0 = kappa5_mu1_m0[perm[n_test:]]\n",
    "\n",
    "# kappa5_mu1_m2\n",
    "perm = rng.permutation(kappa5_mu1_m2.shape[0])\n",
    "n_test = int(0.9*kappa5_mu1_m2.shape[0])\n",
    "kappa5_mu1_m2_test = kappa5_mu1_m2[perm[:n_test]]\n",
    "kappa5_mu1_m2 = kappa5_mu1_m2[perm[n_test:]]\n",
    "\n",
    "# kappa5_mu1_m50\n",
    "perm = rng.permutation(kappa5_mu1_m50.shape[0])\n",
    "n_test = int(0.9*kappa5_mu1_m50.shape[0])\n",
    "kappa5_mu1_m50_test = kappa5_mu1_m50[perm[:n_test]]\n",
    "kappa5_mu1_m50 = kappa5_mu1_m50[perm[n_test:]]\n",
    "\n",
    "# kappa5_mu2_m0\n",
    "perm = rng.permutation(kappa5_mu2_m0.shape[0])\n",
    "n_test = int(0.9*kappa5_mu2_m0.shape[0])\n",
    "kappa5_mu2_m0_test = kappa5_mu2_m0[perm[:n_test]]\n",
    "kappa5_mu2_m0 = kappa5_mu2_m0[perm[n_test:]]\n",
    "\n",
    "# kappa5_mu2_m2\n",
    "perm = rng.permutation(kappa5_mu2_m2.shape[0])\n",
    "n_test = int(0.9*kappa5_mu2_m2.shape[0])\n",
    "kappa5_mu2_m2_test = kappa5_mu2_m2[perm[:n_test]]\n",
    "kappa5_mu2_m2 = kappa5_mu2_m2[perm[n_test:]]\n",
    "\n",
    "# kappa5_mu2_m50\n",
    "perm = rng.permutation(kappa5_mu2_m50.shape[0])\n",
    "n_test = int(0.9*kappa5_mu2_m50.shape[0])\n",
    "kappa5_mu2_m50_test = kappa5_mu2_m50[perm[:n_test]]\n",
    "kappa5_mu2_m50 = kappa5_mu2_m50[perm[n_test:]]\n",
    "\n",
    "# kappa5_mu5_m0\n",
    "perm = rng.permutation(kappa5_mu5_m0.shape[0])\n",
    "n_test = int(0.9*kappa5_mu5_m0.shape[0])\n",
    "kappa5_mu5_m0_test = kappa5_mu5_m0[perm[:n_test]]\n",
    "kappa5_mu5_m0 = kappa5_mu5_m0[perm[n_test:]]\n",
    "\n",
    "# kappa5_mu5_m2\n",
    "perm = rng.permutation(kappa5_mu5_m2.shape[0])\n",
    "n_test = int(0.9*kappa5_mu5_m2.shape[0])\n",
    "kappa5_mu5_m2_test = kappa5_mu5_m2[perm[:n_test]]\n",
    "kappa5_mu5_m2 = kappa5_mu5_m2[perm[n_test:]]\n",
    "\n",
    "# kappa5_mu5_m50\n",
    "perm = rng.permutation(kappa5_mu5_m50.shape[0])\n",
    "n_test = int(0.9*kappa5_mu5_m50.shape[0])\n",
    "kappa5_mu5_m50_test = kappa5_mu5_m50[perm[:n_test]]\n",
    "kappa5_mu5_m50 = kappa5_mu5_m50[perm[n_test:]]\n",
    "\n",
    "# ————————————— Concatenate all training subsamples along axis=0 ————————————— #\n",
    "dataset = np.concatenate(\n",
    "    [\n",
    "        kappa0_mu1_m0,\n",
    "        kappa0_mu1_m2,\n",
    "        kappa0_mu1_m50,\n",
    "        kappa0_mu2_m50,\n",
    "        kappa0_mu5_m50,\n",
    "        kappa5_mu1_m0,\n",
    "        kappa5_mu1_m2,\n",
    "        kappa5_mu1_m50,\n",
    "        kappa5_mu2_m0,\n",
    "        kappa5_mu2_m2,\n",
    "        kappa5_mu2_m50,\n",
    "        kappa5_mu5_m0,\n",
    "        kappa5_mu5_m2,\n",
    "        kappa5_mu5_m50,\n",
    "    ],\n",
    "    axis=0,\n",
    ")\n",
    "\n",
    "print(f\"Original dataset shape: {dataset.shape}\")\n",
    "\n",
    "# Subsample data\n",
    "# dataset = dataset[: int(0.01 * dataset.shape[0]), :]\n",
    "\n",
    "print(f\"Shape of the data after configuration: {dataset.shape}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Getters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6. Implementation getters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_observed_ports(sinr_data, num_observed_ports, total_ports):\n",
    "    \"\"\"\n",
    "    Extracts SINR values for the specified number of observed ports.\n",
    "\n",
    "    The function selects a subset of SINR data by identifying equally spaced ports based on the\n",
    "    number of observed ports specified. It returns the SINR values for these observed ports and\n",
    "    their corresponding indices.\n",
    "\n",
    "    Args:\n",
    "        sinr_data (numpy.ndarray): A 2D array where each row represents an observation and each column\n",
    "                                   represents a port with its corresponding SINR values.\n",
    "        num_observed_ports (int): The number of observed ports to select from the SINR data.\n",
    "        total_ports (int): The total number of ports in the SINR data.\n",
    "\n",
    "    Returns:\n",
    "        observed_sinr (numpy.ndarray): A 2D array containing the SINR values for the observed ports.\n",
    "        observed_indices (numpy.ndarray): A 1D array of the indices corresponding to the observed ports.\n",
    "    \"\"\"\n",
    "    observed_indices = np.linspace(0, total_ports - 1, num_observed_ports, dtype=int)\n",
    "    observed_sinr = sinr_data[:, observed_indices]\n",
    "\n",
    "    return observed_sinr, observed_indices\n",
    "\n",
    "\n",
    "def getOP(\n",
    "    observed_indices: np.ndarray,\n",
    "    predicted_values: np.ndarray,\n",
    "    true_values: np.ndarray,\n",
    "    threshold: float,\n",
    "    snr_linear: float,\n",
    "    total_ports: int,\n",
    ") -> float:\n",
    "    \"\"\"Estimate the outage probability for regression models.\n",
    "\n",
    "    This function compares the predicted and observed signal values at different\n",
    "    channels (ports) and determines whether the chosen signal is above a given threshold.\n",
    "    The outage probability is then computed as the proportion of times the signal falls\n",
    "    below this threshold.\n",
    "\n",
    "    Args:\n",
    "        observed_indices (np.ndarray): Indices of the observed ports (channels).\n",
    "        predicted_values (np.ndarray): Matrix of predicted values for each sample.\n",
    "        true_values (np.ndarray): Ground-truth values for each port.\n",
    "        threshold (float): Threshold value for determining outage.\n",
    "        snr_linear (float): Signal-to-noise ratio in linear scale.\n",
    "\n",
    "    Returns:\n",
    "        float: Estimated outage probability.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize an array with negative infinity to store the observed values\n",
    "    observed_values_matrix = np.full((true_values.shape[0], total_ports), -np.inf, dtype=np.float64)\n",
    "\n",
    "    # Assign the true values of the observed ports (channels) to the matrix\n",
    "    observed_values_matrix[:, observed_indices] = true_values[:, observed_indices]\n",
    "\n",
    "    # Find the index of the highest predicted value for each sample\n",
    "    best_predicted_indices = np.argmax(predicted_values, axis=1)\n",
    "\n",
    "    # Initialize an array with negative infinity to store the predicted values\n",
    "    predicted_values_matrix = np.full((true_values.shape[0], total_ports), -np.inf, dtype=np.float64)\n",
    "\n",
    "    # Assign the true value corresponding to the predicted best port\n",
    "    predicted_values_matrix[np.arange(len(best_predicted_indices)), best_predicted_indices] = true_values[\n",
    "        np.arange(len(best_predicted_indices)), best_predicted_indices\n",
    "    ]\n",
    "\n",
    "    # Take the element-wise maximum between the observed and predicted value matrices\n",
    "    best_value_matrix = np.maximum(observed_values_matrix, predicted_values_matrix)\n",
    "\n",
    "    # print(\"Shape of Best Value Matrix:\", best_value_matrix.shape)\n",
    "\n",
    "    # Find the index of the best predicted or observed port (channel) for each sample\n",
    "    best_predicted_or_observed_ports = np.argmax(best_value_matrix, axis=1)\n",
    "\n",
    "    # print(\"Shape of Best Predicted/Observed Ports:\", best_predicted_or_observed_ports.shape)\n",
    "    # print(\"Number of Selected Ports:\", len(best_predicted_or_observed_ports))\n",
    "\n",
    "    # Retrieve the actual values corresponding to the best selected ports\n",
    "    selected_values = best_value_matrix[np.arange(len(true_values)), best_predicted_or_observed_ports]\n",
    "\n",
    "    # print(\"Shape of Selected Values:\", selected_values.shape)\n",
    "\n",
    "    # Determine which selected values are above the given threshold\n",
    "    above_threshold = selected_values > (threshold / snr_linear)\n",
    "\n",
    "    # print(\"Shape of Above Threshold Array:\", above_threshold.shape)\n",
    "\n",
    "    # Compute the outage probability: probability that the selected value is below the threshold\n",
    "    outage_probability = 1.0 - (np.sum(above_threshold) / len(true_values))\n",
    "\n",
    "    return outage_probability\n",
    "\n",
    "\n",
    "def getObservedOP(\n",
    "    observed_indices: np.ndarray, true_values: np.ndarray, threshold: float, snr_linear: float\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Outage probability when you only observe a subset of ports.\n",
    "\n",
    "    For each sample, picks the best SINR among observed ports,\n",
    "    then computes OP = 1 - P(best_obs > threshold/snr_linear).\n",
    "    \"\"\"\n",
    "    # extract only observed-port SINRs\n",
    "    observed_sinr = true_values[:, observed_indices]\n",
    "    # best per sample\n",
    "    best_obs = np.max(observed_sinr, axis=1)\n",
    "    # fraction above threshold\n",
    "    p_above = np.mean(best_obs > (threshold / snr_linear))\n",
    "    return 1.0 - p_above\n",
    "\n",
    "\n",
    "def getIdealOP(true_values: np.ndarray, threshold: float, snr_linear: float) -> float:\n",
    "    \"\"\"\n",
    "    Genie‐aided outage probability knowing all ports.\n",
    "\n",
    "    For each sample, picks the best SINR across all ports,\n",
    "    then computes OP = 1 - P(best_all > threshold/snr_linear).\n",
    "    \"\"\"\n",
    "    best_all = np.max(true_values, axis=1)\n",
    "    p_above = np.mean(best_all > (threshold / snr_linear))\n",
    "    return 1.0 - p_above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAIN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\n",
    "    kappa0_mu1_m0_test,\n",
    "    kappa0_mu1_m2_test,\n",
    "    kappa0_mu1_m50_test,\n",
    "    kappa0_mu2_m50_test,\n",
    "    kappa0_mu5_m50_test,\n",
    "    kappa5_mu1_m0_test,\n",
    "    kappa5_mu1_m2_test,\n",
    "    kappa5_mu1_m50_test,\n",
    "    kappa5_mu2_m0_test,\n",
    "    kappa5_mu2_m2_test,\n",
    "    kappa5_mu2_m50_test,\n",
    "    kappa5_mu5_m0_test,\n",
    "    kappa5_mu5_m2_test,\n",
    "    kappa5_mu5_m50_test,\n",
    "]\n",
    "\n",
    "dataset_names: list[str] = [\n",
    "    \"kappa0_mu1_m0_test\",\n",
    "    \"kappa0_mu1_m2_test\",\n",
    "    \"kappa0_mu1_m50_test\",\n",
    "    \"kappa0_mu2_m50_test\",\n",
    "    \"kappa0_mu5_m50_test\",\n",
    "    \"kappa5_mu1_m0_test\",\n",
    "    \"kappa5_mu1_m2_test\",\n",
    "    \"kappa5_mu1_m50_test\",\n",
    "    \"kappa5_mu2_m0_test\",\n",
    "    \"kappa5_mu2_m2_test\",\n",
    "    \"kappa5_mu2_m50_test\",\n",
    "    \"kappa5_mu5_m0_test\",\n",
    "    \"kappa5_mu5_m2_test\",\n",
    "    \"kappa5_mu5_m50_test\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1747575156.537679   20089 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2229 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "/home/matheus/anaconda3/envs/tf-optuna/lib/python3.11/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'loss_scale_optimizer', because it has 18 variables whereas the saved optimizer has 14 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/home/matheus/anaconda3/envs/tf-optuna/lib/python3.11/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adamw', because it has 14 variables whereas the saved optimizer has 0 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1747575159.188652   20302 service.cc:148] XLA service 0x760298004dc0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1747575159.188677   20302 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce RTX 3050 Laptop GPU, Compute Capability 8.6\n",
      "2025-05-18 10:32:39.203833: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1747575159.217903   20302 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  123/14063\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 932us/step - loss: 0.4738"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1747575159.718038   20302 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14063/14063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 733us/step - loss: 0.4467\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 738us/step\n",
      "\u001b[1m14063/14063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 653us/step - loss: 0.4433\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 519us/step\n",
      "\u001b[1m14063/14063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 595us/step - loss: 0.4456\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 637us/step\n",
      "\u001b[1m14063/14063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 609us/step - loss: 0.3602\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 621us/step\n",
      "\u001b[1m14063/14063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 688us/step - loss: 0.3001\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 634us/step\n",
      "\u001b[1m14063/14063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 604us/step - loss: 25.8076\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 626us/step\n",
      "\u001b[1m14063/14063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 608us/step - loss: 0.3886\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 643us/step\n",
      "\u001b[1m14063/14063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 612us/step - loss: 0.3252\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 644us/step\n",
      "\u001b[1m14063/14063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 638us/step - loss: 23.8984\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 683us/step\n",
      "\u001b[1m14063/14063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 659us/step - loss: 0.3620\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 692us/step\n",
      "\u001b[1m14063/14063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 741us/step - loss: 0.2924\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 750us/step\n",
      "\u001b[1m14063/14063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 695us/step - loss: 25.2229\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 722us/step\n",
      "\u001b[1m14063/14063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 726us/step - loss: 0.3432\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 684us/step\n",
      "\u001b[1m14063/14063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 679us/step - loss: 0.2702\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 734us/step\n",
      "\n",
      "=== 3 observed ports ===\n",
      "kappa0_mu1_m0_test: Loss=0.446606, OP=0.114351, ObsOP=0.165558\n",
      "kappa0_mu1_m2_test: Loss=0.446039, OP=0.114886, ObsOP=0.166402\n",
      "kappa0_mu1_m50_test: Loss=0.445965, OP=0.114766, ObsOP=0.166164\n",
      "kappa0_mu2_m50_test: Loss=0.360226, OP=0.054236, ObsOP=0.104563\n",
      "kappa0_mu5_m50_test: Loss=0.300120, OP=0.021326, ObsOP=0.066758\n",
      "kappa5_mu1_m0_test: Loss=25.897728, OP=0.930292, ObsOP=0.944756\n",
      "kappa5_mu1_m2_test: Loss=0.388302, OP=0.075191, ObsOP=0.125551\n",
      "kappa5_mu1_m50_test: Loss=0.325283, OP=0.034867, ObsOP=0.080987\n",
      "kappa5_mu2_m0_test: Loss=25.330631, OP=0.958330, ObsOP=0.964358\n",
      "kappa5_mu2_m2_test: Loss=0.360636, OP=0.054264, ObsOP=0.104999\n",
      "kappa5_mu2_m50_test: Loss=0.292173, OP=0.018693, ObsOP=0.062417\n",
      "kappa5_mu5_m0_test: Loss=26.624144, OP=0.970992, ObsOP=0.972241\n",
      "kappa5_mu5_m2_test: Loss=0.342873, OP=0.041679, ObsOP=0.093040\n",
      "kappa5_mu5_m50_test: Loss=0.269986, OP=0.012008, ObsOP=0.055759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matheus/anaconda3/envs/tf-optuna/lib/python3.11/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'loss_scale_optimizer', because it has 18 variables whereas the saved optimizer has 14 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/home/matheus/anaconda3/envs/tf-optuna/lib/python3.11/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adamw', because it has 14 variables whereas the saved optimizer has 0 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14063/14063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 658us/step - loss: 0.1817\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 585us/step\n",
      "\u001b[1m14063/14063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 572us/step - loss: 0.1806\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 595us/step\n",
      "\u001b[1m14063/14063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 660us/step - loss: 0.1809\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 627us/step\n",
      "\u001b[1m14063/14063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 605us/step - loss: 0.1271\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 624us/step\n",
      "\u001b[1m14063/14063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 633us/step - loss: 0.0897\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 622us/step\n",
      "\u001b[1m14063/14063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 653us/step - loss: 0.2542\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 655us/step\n",
      "\u001b[1m14063/14063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 635us/step - loss: 0.1449\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 642us/step\n",
      "\u001b[1m14063/14063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 645us/step - loss: 0.1057\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 623us/step\n",
      "\u001b[1m14063/14063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 629us/step - loss: 0.1225\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 645us/step\n",
      "\u001b[1m14063/14063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 647us/step - loss: 0.1271\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 599us/step\n",
      "\u001b[1m14063/14063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 648us/step - loss: 0.0852\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 698us/step\n",
      "\u001b[1m14063/14063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 619us/step - loss: 0.3713\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 625us/step\n",
      "\u001b[1m14063/14063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 666us/step - loss: 0.1160\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 681us/step\n",
      "\u001b[1m14063/14063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 673us/step - loss: 0.0721\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 655us/step\n",
      "\n",
      "=== 4 observed ports ===\n",
      "kappa0_mu1_m0_test: Loss=0.182197, OP=0.093420, ObsOP=0.101493\n",
      "kappa0_mu1_m2_test: Loss=0.181985, OP=0.094097, ObsOP=0.102356\n",
      "kappa0_mu1_m50_test: Loss=0.180967, OP=0.094007, ObsOP=0.102258\n",
      "kappa0_mu2_m50_test: Loss=0.127123, OP=0.029929, ObsOP=0.035130\n",
      "kappa0_mu5_m50_test: Loss=0.089756, OP=0.003103, ObsOP=0.004466\n",
      "kappa5_mu1_m0_test: Loss=0.275560, OP=0.927430, ObsOP=0.934450\n",
      "kappa5_mu1_m2_test: Loss=0.144858, OP=0.053381, ObsOP=0.059728\n",
      "kappa5_mu1_m50_test: Loss=0.105508, OP=0.014354, ObsOP=0.017607\n",
      "kappa5_mu2_m0_test: Loss=0.144586, OP=0.955527, ObsOP=0.959360\n",
      "kappa5_mu2_m2_test: Loss=0.127176, OP=0.029970, ObsOP=0.035193\n",
      "kappa5_mu2_m50_test: Loss=0.085304, OP=0.002401, ObsOP=0.003438\n",
      "kappa5_mu5_m0_test: Loss=0.237914, OP=0.970624, ObsOP=0.971403\n",
      "kappa5_mu5_m2_test: Loss=0.116001, OP=0.017137, ObsOP=0.021337\n",
      "kappa5_mu5_m50_test: Loss=0.072059, OP=0.000157, ObsOP=0.000308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matheus/anaconda3/envs/tf-optuna/lib/python3.11/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'loss_scale_optimizer', because it has 14 variables whereas the saved optimizer has 10 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/home/matheus/anaconda3/envs/tf-optuna/lib/python3.11/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adamw', because it has 10 variables whereas the saved optimizer has 0 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7032/7032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 703us/step - loss: 0.0484\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 601us/step\n",
      "\u001b[1m7032/7032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 761us/step - loss: 0.0481\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 715us/step\n",
      "\u001b[1m7032/7032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 692us/step - loss: 0.0481\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 673us/step\n",
      "\u001b[1m7032/7032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 637us/step - loss: 0.0415\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 600us/step\n",
      "\u001b[1m7032/7032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 623us/step - loss: 0.0374\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 598us/step\n",
      "\u001b[1m7032/7032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 707us/step - loss: 0.1038\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 695us/step\n",
      "\u001b[1m7032/7032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 632us/step - loss: 0.0432\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 608us/step\n",
      "\u001b[1m7032/7032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 649us/step - loss: 0.0391\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 609us/step\n",
      "\u001b[1m7032/7032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 645us/step - loss: 0.0696\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 615us/step\n",
      "\u001b[1m7032/7032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 622us/step - loss: 0.0412\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 589us/step\n",
      "\u001b[1m7032/7032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 628us/step - loss: 0.0369\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 622us/step\n",
      "\u001b[1m7032/7032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 683us/step - loss: 0.0950\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 591us/step\n",
      "\u001b[1m7032/7032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 629us/step - loss: 0.0402\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 606us/step\n",
      "\u001b[1m7032/7032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 621us/step - loss: 0.0356\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 585us/step\n",
      "\n",
      "=== 5 observed ports ===\n",
      "kappa0_mu1_m0_test: Loss=0.048300, OP=0.081190, ObsOP=0.089720\n",
      "kappa0_mu1_m2_test: Loss=0.048241, OP=0.081806, ObsOP=0.090498\n",
      "kappa0_mu1_m50_test: Loss=0.048121, OP=0.081796, ObsOP=0.090548\n",
      "kappa0_mu2_m50_test: Loss=0.041345, OP=0.025150, ObsOP=0.030241\n",
      "kappa0_mu5_m50_test: Loss=0.037503, OP=0.002366, ObsOP=0.003408\n",
      "kappa5_mu1_m0_test: Loss=0.118476, OP=0.917290, ObsOP=0.927051\n",
      "kappa5_mu1_m2_test: Loss=0.043198, OP=0.044790, ObsOP=0.051219\n",
      "kappa5_mu1_m50_test: Loss=0.038999, OP=0.011314, ObsOP=0.014211\n",
      "kappa5_mu2_m0_test: Loss=0.091042, OP=0.952561, ObsOP=0.956963\n",
      "kappa5_mu2_m2_test: Loss=0.041246, OP=0.025023, ObsOP=0.030096\n",
      "kappa5_mu2_m50_test: Loss=0.036977, OP=0.001801, ObsOP=0.002562\n",
      "kappa5_mu5_m0_test: Loss=0.077276, OP=0.970071, ObsOP=0.970601\n",
      "kappa5_mu5_m2_test: Loss=0.040251, OP=0.014283, ObsOP=0.017963\n",
      "kappa5_mu5_m50_test: Loss=0.035500, OP=0.000086, ObsOP=0.000141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matheus/anaconda3/envs/tf-optuna/lib/python3.11/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'loss_scale_optimizer', because it has 22 variables whereas the saved optimizer has 18 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/home/matheus/anaconda3/envs/tf-optuna/lib/python3.11/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adamw', because it has 18 variables whereas the saved optimizer has 0 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14063/14063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 636us/step - loss: 0.0022\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 663us/step\n",
      "\u001b[1m14063/14063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 673us/step - loss: 0.0022\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 654us/step\n",
      "\u001b[1m14063/14063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 710us/step - loss: 0.0022\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 694us/step\n",
      "\u001b[1m14063/14063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 790us/step - loss: 0.0016\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 771us/step\n",
      "\u001b[1m14063/14063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 694us/step - loss: 0.0013\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 725us/step\n",
      "\u001b[1m14063/14063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 785us/step - loss: 0.0198\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 732us/step\n",
      "\u001b[1m14063/14063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 631us/step - loss: 0.0017\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 677us/step\n",
      "\u001b[1m14063/14063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 691us/step - loss: 0.0014\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 693us/step\n",
      "\u001b[1m14063/14063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 654us/step - loss: 0.0134\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 649us/step\n",
      "\u001b[1m14063/14063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 670us/step - loss: 0.0016\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 684us/step\n",
      "\u001b[1m14063/14063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 732us/step - loss: 0.0013\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 674us/step\n",
      "\u001b[1m14063/14063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 696us/step - loss: 0.0236\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 736us/step\n",
      "\u001b[1m14063/14063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 688us/step - loss: 0.0015\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 706us/step\n",
      "\u001b[1m14063/14063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 751us/step - loss: 0.0012\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 737us/step\n",
      "\n",
      "=== 6 observed ports ===\n",
      "kappa0_mu1_m0_test: Loss=0.002156, OP=0.075288, ObsOP=0.083758\n",
      "kappa0_mu1_m2_test: Loss=0.002162, OP=0.075818, ObsOP=0.084450\n",
      "kappa0_mu1_m50_test: Loss=0.002155, OP=0.075789, ObsOP=0.084633\n",
      "kappa0_mu2_m50_test: Loss=0.001564, OP=0.020760, ObsOP=0.025127\n",
      "kappa0_mu5_m50_test: Loss=0.001297, OP=0.001257, ObsOP=0.001837\n",
      "kappa5_mu1_m0_test: Loss=0.021789, OP=0.911583, ObsOP=0.922410\n",
      "kappa5_mu1_m2_test: Loss=0.001714, OP=0.039950, ObsOP=0.046130\n",
      "kappa5_mu1_m50_test: Loss=0.001394, OP=0.008728, ObsOP=0.011082\n",
      "kappa5_mu2_m0_test: Loss=0.016176, OP=0.949359, ObsOP=0.954537\n",
      "kappa5_mu2_m2_test: Loss=0.001558, OP=0.020747, ObsOP=0.024991\n",
      "kappa5_mu2_m50_test: Loss=0.001270, OP=0.000914, ObsOP=0.001338\n",
      "kappa5_mu5_m0_test: Loss=0.018172, OP=0.969480, ObsOP=0.970340\n",
      "kappa5_mu5_m2_test: Loss=0.001472, OP=0.010652, ObsOP=0.013648\n",
      "kappa5_mu5_m50_test: Loss=0.001206, OP=0.000017, ObsOP=0.000034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matheus/anaconda3/envs/tf-optuna/lib/python3.11/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'loss_scale_optimizer', because it has 22 variables whereas the saved optimizer has 18 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/home/matheus/anaconda3/envs/tf-optuna/lib/python3.11/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adamw', because it has 18 variables whereas the saved optimizer has 0 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14063/14063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 766us/step - loss: 1.7511e-04\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 769us/step\n",
      "\u001b[1m14063/14063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 799us/step - loss: 1.7365e-04\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 663us/step\n",
      "\u001b[1m14063/14063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 717us/step - loss: 1.7432e-04\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 666us/step\n",
      "\u001b[1m14063/14063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 697us/step - loss: 1.2629e-04\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 726us/step\n",
      "\u001b[1m14063/14063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 774us/step - loss: 1.1327e-04\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 724us/step\n",
      "\u001b[1m14063/14063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 826us/step - loss: 0.0123\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 705us/step\n",
      "\u001b[1m14063/14063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 799us/step - loss: 1.3532e-04\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 724us/step\n",
      "\u001b[1m14063/14063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 714us/step - loss: 1.1643e-04\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 665us/step\n",
      "\u001b[1m14063/14063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 715us/step - loss: 0.0075\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 571us/step\n",
      "\u001b[1m14063/14063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 587us/step - loss: 1.2568e-04\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 548us/step\n",
      "\u001b[1m14063/14063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 589us/step - loss: 1.1225e-04\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 547us/step\n",
      "\u001b[1m14063/14063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 581us/step - loss: 0.0191\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 551us/step\n",
      "\u001b[1m14063/14063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 605us/step - loss: 1.2129e-04\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 553us/step\n",
      "\u001b[1m14063/14063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 577us/step - loss: 1.1014e-04\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 560us/step\n",
      "\n",
      "=== 7 observed ports ===\n",
      "kappa0_mu1_m0_test: Loss=0.000175, OP=0.074729, ObsOP=0.080878\n",
      "kappa0_mu1_m2_test: Loss=0.000175, OP=0.075258, ObsOP=0.081499\n",
      "kappa0_mu1_m50_test: Loss=0.000173, OP=0.075236, ObsOP=0.081584\n",
      "kappa0_mu2_m50_test: Loss=0.000126, OP=0.020518, ObsOP=0.023697\n",
      "kappa0_mu5_m50_test: Loss=0.000113, OP=0.001210, ObsOP=0.001624\n",
      "kappa5_mu1_m0_test: Loss=0.013171, OP=0.911199, ObsOP=0.919340\n",
      "kappa5_mu1_m2_test: Loss=0.000135, OP=0.039541, ObsOP=0.044019\n",
      "kappa5_mu1_m50_test: Loss=0.000117, OP=0.008594, ObsOP=0.010308\n",
      "kappa5_mu2_m0_test: Loss=0.009995, OP=0.949143, ObsOP=0.953604\n",
      "kappa5_mu2_m2_test: Loss=0.000126, OP=0.020482, ObsOP=0.023709\n",
      "kappa5_mu2_m50_test: Loss=0.000112, OP=0.000898, ObsOP=0.001189\n",
      "kappa5_mu5_m0_test: Loss=0.016323, OP=0.969438, ObsOP=0.970341\n",
      "kappa5_mu5_m2_test: Loss=0.000121, OP=0.010454, ObsOP=0.012718\n",
      "kappa5_mu5_m50_test: Loss=0.000110, OP=0.000013, ObsOP=0.000023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matheus/anaconda3/envs/tf-optuna/lib/python3.11/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'loss_scale_optimizer', because it has 18 variables whereas the saved optimizer has 14 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/home/matheus/anaconda3/envs/tf-optuna/lib/python3.11/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adamw', because it has 14 variables whereas the saved optimizer has 0 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3516/3516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 988us/step - loss: 1.7924e-04\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 530us/step\n",
      "\u001b[1m3516/3516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 932us/step - loss: 1.7822e-04\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 523us/step\n",
      "\u001b[1m3516/3516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 928us/step - loss: 1.7774e-04\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 517us/step\n",
      "\u001b[1m3516/3516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 943us/step - loss: 1.1905e-04\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 518us/step\n",
      "\u001b[1m3516/3516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 9.8655e-05\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 782us/step\n",
      "\u001b[1m3516/3516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 976us/step - loss: 0.0334\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 580us/step\n",
      "\u001b[1m3516/3516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 990us/step - loss: 1.3137e-04\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 618us/step\n",
      "\u001b[1m3516/3516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 964us/step - loss: 1.0577e-04\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 599us/step\n",
      "\u001b[1m3516/3516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 954us/step - loss: 0.0210\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 580us/step\n",
      "\u001b[1m3516/3516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 923us/step - loss: 1.1862e-04\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 514us/step\n",
      "\u001b[1m3516/3516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 904us/step - loss: 9.6492e-05\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 507us/step\n",
      "\u001b[1m3516/3516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 941us/step - loss: 0.0414\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 522us/step\n",
      "\u001b[1m3516/3516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 902us/step - loss: 1.1191e-04\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 556us/step\n",
      "\u001b[1m3516/3516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 9.1234e-05\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 548us/step\n",
      "\n",
      "=== 10 observed ports ===\n",
      "kappa0_mu1_m0_test: Loss=0.000179, OP=0.074740, ObsOP=0.077329\n",
      "kappa0_mu1_m2_test: Loss=0.000179, OP=0.075279, ObsOP=0.077912\n",
      "kappa0_mu1_m50_test: Loss=0.000177, OP=0.075244, ObsOP=0.077930\n",
      "kappa0_mu2_m50_test: Loss=0.000119, OP=0.020519, ObsOP=0.021792\n",
      "kappa0_mu5_m50_test: Loss=0.000099, OP=0.001212, ObsOP=0.001369\n",
      "kappa5_mu1_m0_test: Loss=0.032257, OP=0.911218, ObsOP=0.914979\n",
      "kappa5_mu1_m2_test: Loss=0.000131, OP=0.039554, ObsOP=0.041417\n",
      "kappa5_mu1_m50_test: Loss=0.000106, OP=0.008597, ObsOP=0.009273\n",
      "kappa5_mu2_m0_test: Loss=0.029444, OP=0.949170, ObsOP=0.951312\n",
      "kappa5_mu2_m2_test: Loss=0.000119, OP=0.020482, ObsOP=0.021796\n",
      "kappa5_mu2_m50_test: Loss=0.000096, OP=0.000894, ObsOP=0.001003\n",
      "kappa5_mu5_m0_test: Loss=0.042656, OP=0.969436, ObsOP=0.969844\n",
      "kappa5_mu5_m2_test: Loss=0.000112, OP=0.010443, ObsOP=0.011313\n",
      "kappa5_mu5_m50_test: Loss=0.000091, OP=0.000013, ObsOP=0.000018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matheus/anaconda3/envs/tf-optuna/lib/python3.11/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'loss_scale_optimizer', because it has 18 variables whereas the saved optimizer has 14 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/home/matheus/anaconda3/envs/tf-optuna/lib/python3.11/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adamw', because it has 14 variables whereas the saved optimizer has 0 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7032/7032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 889us/step - loss: 4.8018e-04\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 494us/step\n",
      "\u001b[1m7032/7032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 841us/step - loss: 4.7733e-04\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 470us/step\n",
      "\u001b[1m7032/7032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 875us/step - loss: 4.7836e-04\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 497us/step\n",
      "\u001b[1m7032/7032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 878us/step - loss: 3.4499e-04\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 536us/step\n",
      "\u001b[1m7032/7032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 844us/step - loss: 2.7937e-04\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 502us/step\n",
      "\u001b[1m7032/7032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 849us/step - loss: 0.0389\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 503us/step\n",
      "\u001b[1m7032/7032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 851us/step - loss: 3.8022e-04\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 498us/step\n",
      "\u001b[1m7032/7032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 850us/step - loss: 3.0530e-04\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 511us/step\n",
      "\u001b[1m7032/7032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 866us/step - loss: 0.0242\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 530us/step\n",
      "\u001b[1m7032/7032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 867us/step - loss: 3.4593e-04\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 521us/step\n",
      "\u001b[1m7032/7032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 837us/step - loss: 2.7197e-04\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 571us/step\n",
      "\u001b[1m7032/7032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 830us/step - loss: 0.0403\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 495us/step\n",
      "\u001b[1m7032/7032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 900us/step - loss: 3.2482e-04\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 538us/step\n",
      "\u001b[1m7032/7032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 896us/step - loss: 2.5277e-04\n",
      "\u001b[1m28125/28125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 489us/step\n",
      "\n",
      "=== 15 observed ports ===\n",
      "kappa0_mu1_m0_test: Loss=0.000479, OP=0.074803, ObsOP=0.075734\n",
      "kappa0_mu1_m2_test: Loss=0.000479, OP=0.075337, ObsOP=0.076290\n",
      "kappa0_mu1_m50_test: Loss=0.000476, OP=0.075321, ObsOP=0.076287\n",
      "kappa0_mu2_m50_test: Loss=0.000345, OP=0.020551, ObsOP=0.021000\n",
      "kappa0_mu5_m50_test: Loss=0.000280, OP=0.001216, ObsOP=0.001277\n",
      "kappa5_mu1_m0_test: Loss=0.040111, OP=0.911346, ObsOP=0.912819\n",
      "kappa5_mu1_m2_test: Loss=0.000380, OP=0.039598, ObsOP=0.040286\n",
      "kappa5_mu1_m50_test: Loss=0.000305, OP=0.008616, ObsOP=0.008852\n",
      "kappa5_mu2_m0_test: Loss=0.031087, OP=0.949248, ObsOP=0.950078\n",
      "kappa5_mu2_m2_test: Loss=0.000346, OP=0.020508, ObsOP=0.021006\n",
      "kappa5_mu2_m50_test: Loss=0.000272, OP=0.000900, ObsOP=0.000926\n",
      "kappa5_mu5_m0_test: Loss=0.040671, OP=0.969448, ObsOP=0.969622\n",
      "kappa5_mu5_m2_test: Loss=0.000325, OP=0.010487, ObsOP=0.010792\n",
      "kappa5_mu5_m50_test: Loss=0.000253, OP=0.000014, ObsOP=0.000016\n",
      "\n",
      "=== Ideal Outage Probability (genie-aided) per dataset ===\n",
      "kappa0_mu1_m0_test: IdealOP=0.074659\n",
      "kappa0_mu1_m2_test: IdealOP=0.075188\n",
      "kappa0_mu1_m50_test: IdealOP=0.075157\n",
      "kappa0_mu2_m50_test: IdealOP=0.020477\n",
      "kappa0_mu5_m50_test: IdealOP=0.001201\n",
      "kappa5_mu1_m0_test: IdealOP=0.911136\n",
      "kappa5_mu1_m2_test: IdealOP=0.039483\n",
      "kappa5_mu1_m50_test: IdealOP=0.008571\n",
      "kappa5_mu2_m0_test: IdealOP=0.949119\n",
      "kappa5_mu2_m2_test: IdealOP=0.020428\n",
      "kappa5_mu2_m50_test: IdealOP=0.000891\n",
      "kappa5_mu5_m0_test: IdealOP=0.969417\n",
      "kappa5_mu5_m2_test: IdealOP=0.010421\n",
      "kappa5_mu5_m50_test: IdealOP=0.000013\n"
     ]
    }
   ],
   "source": [
    "# Precompute ideal OP once per dataset\n",
    "ideal_ops_global = [\n",
    "    getIdealOP(data, THRESHOLD, SNR_LINEAR)\n",
    "    for data in datasets\n",
    "]\n",
    "\n",
    "for n_ports, model_path, batch_size, scaler in zip(observed_ports_list, model_paths, batch_sizes, scalers):\n",
    "    # create and/or clear subfolder\n",
    "    sub_dir = os.path.join(RUN_DIR, f\"op_{n_ports}_observed_ports\")\n",
    "    os.makedirs(sub_dir, exist_ok=True)\n",
    "\n",
    "    # load the single model for this n_ports\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "    # fit scaler on training split observed at n_ports\n",
    "    observed_ports, _ = get_observed_ports(dataset, n_ports, TOTAL_NUM_PORTS)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        observed_ports, dataset, test_size=0.2, random_state=0, shuffle=True\n",
    "    )\n",
    "    scaler.fit(X_train)\n",
    "\n",
    "    test_losses = []\n",
    "    ops = []\n",
    "    obs_ops = []\n",
    "\n",
    "    # evaluate on each test subset\n",
    "    for data, name in zip(datasets, dataset_names):\n",
    "        X_test, idxs = get_observed_ports(data, n_ports, TOTAL_NUM_PORTS)\n",
    "        X_test = scaler.transform(X_test).reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "        loss = model.evaluate(X_test, data, batch_size=batch_size, verbose=1)\n",
    "        test_losses.append(loss)\n",
    "\n",
    "        y_pred = model.predict(X_test, verbose=1)\n",
    "        op = getOP(idxs, y_pred, data, THRESHOLD, SNR_LINEAR, TOTAL_NUM_PORTS)\n",
    "        ops.append(op)\n",
    "        \n",
    "        # compute observed-only OP\n",
    "        obs_op = getObservedOP(idxs, data, THRESHOLD, SNR_LINEAR)\n",
    "        obs_ops.append(obs_op)\n",
    "\n",
    "    # print a concise summary\n",
    "    print(f\"\\n=== {n_ports} observed ports ===\")\n",
    "    for name, loss, op, obs_op, ideal_op in zip(\n",
    "        dataset_names, test_losses, ops, obs_ops, ideal_ops_global\n",
    "    ):\n",
    "        print(f\"{name}: Loss={loss:.6f}, OP={op:.6f}, ObsOP={obs_op:.6f}\")\n",
    "\n",
    "    # save results to file\n",
    "    results = {f\"{n}_loss\": l for n, l in zip(dataset_names, test_losses)}\n",
    "    results.update({f\"{n}_op\": o for n, o in zip(dataset_names, ops)})\n",
    "    results.update({f\"{n}_obsOP\": o for n, o in zip(dataset_names, obs_ops)})\n",
    "\n",
    "    out_file = os.path.join(sub_dir, f\"results_{n_ports}_ports.txt\")\n",
    "    troo.save_trial_params_to_file(filepath=out_file, params={}, **results)\n",
    "    \n",
    "# 3. Global ideal-OP section (once per dataset)\n",
    "print(\"\\n=== Ideal Outage Probability (genie-aided) per dataset ===\")\n",
    "for name, ideal_op in zip(dataset_names, ideal_ops_global):\n",
    "    print(f\"{name}: IdealOP={ideal_op:.6f}\")\n",
    "\n",
    "# (Optional) save to a dedicated file\n",
    "ideal_results = {f\"{n}_idealOP\": o for n, o in zip(dataset_names, ideal_ops_global)}\n",
    "ideal_file = os.path.join(RUN_DIR, \"ideal_ops_global.txt\")\n",
    "troo.save_trial_params_to_file(filepath=ideal_file, params={}, **ideal_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-optuna",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
