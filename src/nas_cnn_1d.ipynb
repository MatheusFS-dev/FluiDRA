{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NAS - Optuna\n",
    "\n",
    "- **Authored by:** Matheus Ferreira Silva \n",
    "- **GitHub:**: https://github.com/MatheusFS-dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Async CUDA allocator\n",
    "os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'\n",
    "\n",
    "# If cuDNN autotune fails, fall back to a safe (but slower) algorithm.\n",
    "os.environ[\"XLA_FLAGS\"] = \"--xla_gpu_strict_conv_algorithm_picker=false\"\n",
    "\n",
    "# Allow TensorFlow to allocate GPU memory as needed\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from _imports import * # Centralized file containing all imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. GPU Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify GPU to use (e.g., GPU 0)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Run Parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TRIALS = 200\n",
    "EPOCHS = 50\n",
    "TOP_K = 5  # Number of top trials to save\n",
    "\n",
    "TOTAL_NUM_PORTS = 100\n",
    "observed_ports_list = [3, 4, 5, 6, 7, 10, 15]\n",
    "\n",
    "THRESHOLD = 1\n",
    "SNR_LINEAR = 2.5\n",
    "\n",
    "mixed_precision.set_global_policy(\"mixed_float16\")\n",
    "\n",
    "#? Set to an existing path to resume training\n",
    "RESUME_TRAINING_PATH = \"runs/nas_cnn1d_v0\" # None or \"runs/nas_1\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_DIR = RESUME_TRAINING_PATH\n",
    "print(f\"Run directory: {RUN_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------- Load the dataset in matlab format -------------------- #\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "kappa0_mu1_m0 = scipy.io.loadmat(\"./data/w1_u1_n100/SNR_events_W1.0_U1_N100_kappa1.0e-16_mu1.0_m0.0.mat\")[\"SNR_events\"]\n",
    "kappa0_mu1_m2 = scipy.io.loadmat(\"./data/w1_u1_n100/SNR_events_W1.0_U1_N100_kappa1.0e-16_mu1.0_m2.0.mat\")[\"SNR_events\"]\n",
    "kappa0_mu1_m50 = scipy.io.loadmat(\"./data/w1_u1_n100/SNR_events_W1.0_U1_N100_kappa1.0e-16_mu1.0_m50.0.mat\")[\"SNR_events\"]\n",
    "kappa0_mu2_m50 = scipy.io.loadmat(\"./data/w1_u1_n100/SNR_events_W1.0_U1_N100_kappa1.0e-16_mu2.0_m50.0.mat\")[\"SNR_events\"]\n",
    "kappa0_mu5_m50 = scipy.io.loadmat(\"./data/w1_u1_n100/SNR_events_W1.0_U1_N100_kappa1.0e-16_mu5.0_m50.0.mat\")[\"SNR_events\"]\n",
    "kappa5_mu1_m0 = scipy.io.loadmat(\"./data/w1_u1_n100/SNR_events_W1.0_U1_N100_kappa5.0e+00_mu1.0_m0.0.mat\")[\"SNR_events\"]\n",
    "kappa5_mu1_m2 = scipy.io.loadmat(\"./data/w1_u1_n100/SNR_events_W1.0_U1_N100_kappa5.0e+00_mu1.0_m2.0.mat\")[\"SNR_events\"]\n",
    "kappa5_mu1_m50 = scipy.io.loadmat(\"./data/w1_u1_n100/SNR_events_W1.0_U1_N100_kappa5.0e+00_mu1.0_m50.0.mat\")[\"SNR_events\"]\n",
    "kappa5_mu2_m0 = scipy.io.loadmat(\"./data/w1_u1_n100/SNR_events_W1.0_U1_N100_kappa5.0e+00_mu2.0_m0.0.mat\")[\"SNR_events\"]\n",
    "kappa5_mu2_m2 = scipy.io.loadmat(\"./data/w1_u1_n100/SNR_events_W1.0_U1_N100_kappa5.0e+00_mu2.0_m2.0.mat\")[\"SNR_events\"]\n",
    "kappa5_mu2_m50 = scipy.io.loadmat(\"./data/w1_u1_n100/SNR_events_W1.0_U1_N100_kappa5.0e+00_mu2.0_m50.0.mat\")[\"SNR_events\"]\n",
    "kappa5_mu5_m0 = scipy.io.loadmat(\"./data/w1_u1_n100/SNR_events_W1.0_U1_N100_kappa5.0e+00_mu5.0_m0.0.mat\")[\"SNR_events\"]\n",
    "kappa5_mu5_m2 = scipy.io.loadmat(\"./data/w1_u1_n100/SNR_events_W1.0_U1_N100_kappa5.0e+00_mu5.0_m2.0.mat\")[\"SNR_events\"]\n",
    "kappa5_mu5_m50 = scipy.io.loadmat(\"./data/w1_u1_n100/SNR_events_W1.0_U1_N100_kappa5.0e+00_mu5.0_m50.0.mat\")[\"SNR_events\"]\n",
    "\n",
    "# ————————————— Split the data into 10% training and 90% testing ————————————— #\n",
    "\n",
    "# kappa0_mu1_m0\n",
    "perm = rng.permutation(kappa0_mu1_m0.shape[0])\n",
    "n_test = int(0.9*kappa0_mu1_m0.shape[0])\n",
    "kappa0_mu1_m0_test = kappa0_mu1_m0[perm[:n_test]]\n",
    "kappa0_mu1_m0 = kappa0_mu1_m0[perm[n_test:]]\n",
    "\n",
    "# kappa0_mu1_m2\n",
    "perm = rng.permutation(kappa0_mu1_m2.shape[0])\n",
    "n_test = int(0.9*kappa0_mu1_m2.shape[0])\n",
    "kappa0_mu1_m2_test = kappa0_mu1_m2[perm[:n_test]]\n",
    "kappa0_mu1_m2 = kappa0_mu1_m2[perm[n_test:]]\n",
    "\n",
    "# kappa0_mu1_m50\n",
    "perm = rng.permutation(kappa0_mu1_m50.shape[0])\n",
    "n_test = int(0.9*kappa0_mu1_m50.shape[0])\n",
    "kappa0_mu1_m50_test = kappa0_mu1_m50[perm[:n_test]]\n",
    "kappa0_mu1_m50 = kappa0_mu1_m50[perm[n_test:]]\n",
    "\n",
    "# kappa0_mu2_m50\n",
    "perm = rng.permutation(kappa0_mu2_m50.shape[0])\n",
    "n_test = int(0.9*kappa0_mu2_m50.shape[0])\n",
    "kappa0_mu2_m50_test = kappa0_mu2_m50[perm[:n_test]]\n",
    "kappa0_mu2_m50 = kappa0_mu2_m50[perm[n_test:]]\n",
    "\n",
    "# kappa0_mu5_m50\n",
    "perm = rng.permutation(kappa0_mu5_m50.shape[0])\n",
    "n_test = int(0.9*kappa0_mu5_m50.shape[0])\n",
    "kappa0_mu5_m50_test = kappa0_mu5_m50[perm[:n_test]]\n",
    "kappa0_mu5_m50 = kappa0_mu5_m50[perm[n_test:]]\n",
    "\n",
    "# kappa5_mu1_m0\n",
    "perm = rng.permutation(kappa5_mu1_m0.shape[0])\n",
    "n_test = int(0.9*kappa5_mu1_m0.shape[0])\n",
    "kappa5_mu1_m0_test = kappa5_mu1_m0[perm[:n_test]]\n",
    "kappa5_mu1_m0 = kappa5_mu1_m0[perm[n_test:]]\n",
    "\n",
    "# kappa5_mu1_m2\n",
    "perm = rng.permutation(kappa5_mu1_m2.shape[0])\n",
    "n_test = int(0.9*kappa5_mu1_m2.shape[0])\n",
    "kappa5_mu1_m2_test = kappa5_mu1_m2[perm[:n_test]]\n",
    "kappa5_mu1_m2 = kappa5_mu1_m2[perm[n_test:]]\n",
    "\n",
    "# kappa5_mu1_m50\n",
    "perm = rng.permutation(kappa5_mu1_m50.shape[0])\n",
    "n_test = int(0.9*kappa5_mu1_m50.shape[0])\n",
    "kappa5_mu1_m50_test = kappa5_mu1_m50[perm[:n_test]]\n",
    "kappa5_mu1_m50 = kappa5_mu1_m50[perm[n_test:]]\n",
    "\n",
    "# kappa5_mu2_m0\n",
    "perm = rng.permutation(kappa5_mu2_m0.shape[0])\n",
    "n_test = int(0.9*kappa5_mu2_m0.shape[0])\n",
    "kappa5_mu2_m0_test = kappa5_mu2_m0[perm[:n_test]]\n",
    "kappa5_mu2_m0 = kappa5_mu2_m0[perm[n_test:]]\n",
    "\n",
    "# kappa5_mu2_m2\n",
    "perm = rng.permutation(kappa5_mu2_m2.shape[0])\n",
    "n_test = int(0.9*kappa5_mu2_m2.shape[0])\n",
    "kappa5_mu2_m2_test = kappa5_mu2_m2[perm[:n_test]]\n",
    "kappa5_mu2_m2 = kappa5_mu2_m2[perm[n_test:]]\n",
    "\n",
    "# kappa5_mu2_m50\n",
    "perm = rng.permutation(kappa5_mu2_m50.shape[0])\n",
    "n_test = int(0.9*kappa5_mu2_m50.shape[0])\n",
    "kappa5_mu2_m50_test = kappa5_mu2_m50[perm[:n_test]]\n",
    "kappa5_mu2_m50 = kappa5_mu2_m50[perm[n_test:]]\n",
    "\n",
    "# kappa5_mu5_m0\n",
    "perm = rng.permutation(kappa5_mu5_m0.shape[0])\n",
    "n_test = int(0.9*kappa5_mu5_m0.shape[0])\n",
    "kappa5_mu5_m0_test = kappa5_mu5_m0[perm[:n_test]]\n",
    "kappa5_mu5_m0 = kappa5_mu5_m0[perm[n_test:]]\n",
    "\n",
    "# kappa5_mu5_m2\n",
    "perm = rng.permutation(kappa5_mu5_m2.shape[0])\n",
    "n_test = int(0.9*kappa5_mu5_m2.shape[0])\n",
    "kappa5_mu5_m2_test = kappa5_mu5_m2[perm[:n_test]]\n",
    "kappa5_mu5_m2 = kappa5_mu5_m2[perm[n_test:]]\n",
    "\n",
    "# kappa5_mu5_m50\n",
    "perm = rng.permutation(kappa5_mu5_m50.shape[0])\n",
    "n_test = int(0.9*kappa5_mu5_m50.shape[0])\n",
    "kappa5_mu5_m50_test = kappa5_mu5_m50[perm[:n_test]]\n",
    "kappa5_mu5_m50 = kappa5_mu5_m50[perm[n_test:]]\n",
    "\n",
    "# ————————————— Concatenate all training subsamples along axis=0 ————————————— #\n",
    "dataset = np.concatenate(\n",
    "    [\n",
    "        kappa0_mu1_m0,\n",
    "        kappa0_mu1_m2,\n",
    "        kappa0_mu1_m50,\n",
    "        kappa0_mu2_m50,\n",
    "        kappa0_mu5_m50,\n",
    "        kappa5_mu1_m0,\n",
    "        kappa5_mu1_m2,\n",
    "        kappa5_mu1_m50,\n",
    "        kappa5_mu2_m0,\n",
    "        kappa5_mu2_m2,\n",
    "        kappa5_mu2_m50,\n",
    "        kappa5_mu5_m0,\n",
    "        kappa5_mu5_m2,\n",
    "        kappa5_mu5_m50,\n",
    "    ],\n",
    "    axis=0,\n",
    ")\n",
    "\n",
    "print(f\"Original dataset shape: {dataset.shape}\")\n",
    "\n",
    "# Subsample data\n",
    "# dataset = dataset[: int(0.01 * dataset.shape[0]), :]\n",
    "\n",
    "print(f\"Shape of the data after configuration: {dataset.shape}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Getters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_regularizer(trial: optuna.Trial, name: str) -> Optional[tf.keras.regularizers.Regularizer]:\n",
    "    \"\"\"\n",
    "    Suggests a regularization strategy using Optuna and returns the corresponding Keras regularizer.\n",
    "    \n",
    "    Args:\n",
    "        trial (optuna.Trial): Optuna trial object used to sample the regularizer.\n",
    "        name (str): Unique identifier for this regularizer parameter (used as key).\n",
    "\n",
    "    Returns:\n",
    "        Optional[tf.keras.regularizers.Regularizer]: The selected Keras regularizer instance,\n",
    "        or `None` if \"none\" was selected.\n",
    "    \"\"\"\n",
    "    # Suggest a regularizer type\n",
    "    reg_type: str = trial.suggest_categorical(\n",
    "        name,\n",
    "        [\n",
    "            \"none\",\n",
    "            \"l1\",\n",
    "            \"l2\",\n",
    "            \"l1l2\",\n",
    "            # \"orthogonal\",  #! only works for rank-2 tensors\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # Map each regularizer name to a corresponding Keras regularizer instance\n",
    "    regularizer_map: Dict[str, Optional[tf.keras.regularizers.Regularizer]] = {\n",
    "        \"none\": None,\n",
    "        \"l1\": regularizers.L1(l1=0.01),\n",
    "        \"l2\": regularizers.L2(l2=0.01),\n",
    "        \"l1l2\": regularizers.L1L2(l1=0.01, l2=0.01),\n",
    "        \"orthogonal\": regularizers.OrthogonalRegularizer(factor=0.01, mode=\"rows\"),\n",
    "    }\n",
    "\n",
    "    # Return the appropriate regularizer, or None if not found\n",
    "    return regularizer_map.get(reg_type, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Activation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activation(trial: Any, name: str) -> Union[str, Callable[..., layers.Layer]]:\n",
    "    \"\"\"\n",
    "    Suggests an activation function from a predefined list using Optuna.\n",
    "\n",
    "    Args:\n",
    "        trial (Any): The Optuna trial instance used to suggest a value.\n",
    "        name (str): A unique name for this hyperparameter (e.g., \"layer_1_activation\").\n",
    "\n",
    "    Returns:\n",
    "        Union[str, Callable[..., layers.Layer]]: A string representing the activation function.\n",
    "        This can be passed directly into a Keras layer's `activation=` argument.\n",
    "    \"\"\"\n",
    "    return trial.suggest_categorical(\n",
    "        name,\n",
    "        [\n",
    "            \"relu\",\n",
    "            \"tanh\",\n",
    "            \"sigmoid\",  # Logistic\n",
    "            \"elu\", \n",
    "            \"swish\",  # x * sigmoid(x)\n",
    "            \"leaky_relu\",\n",
    "        ],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer(trial: optuna.Trial) -> tf.keras.optimizers.Optimizer:\n",
    "    \"\"\"\n",
    "    Suggests and returns a TensorFlow optimizer with a trial-based learning rate.\n",
    "\n",
    "    Args:\n",
    "        trial (optuna.Trial): Optuna trial object used for hyperparameter suggestion.\n",
    "\n",
    "    Returns:\n",
    "        tf.keras.optimizers.Optimizer: An instance of the selected optimizer.\n",
    "    \"\"\"\n",
    "    # Suggest optimizer name from a predefined categorical set\n",
    "    optimizer_name = trial.suggest_categorical(\n",
    "        \"optimizer\",\n",
    "        [\n",
    "            \"AdamW\",\n",
    "            # \"SGD\",\n",
    "            # \"Adam\",\n",
    "            # \"RMSprop\",\n",
    "            # \"Nadam\",\n",
    "            # \"Lion\",\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # Suggest learning rate on a logarithmic scale between 1e-5 and 1e-2\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-2, log=True)\n",
    "\n",
    "    # Mapping of optimizer names to their TensorFlow classes\n",
    "    optimizer_map: Dict[str, Type[tf.keras.optimizers.Optimizer]] = {\n",
    "        \"Adam\": optimizers.Adam,\n",
    "        \"AdamW\": optimizers.AdamW,\n",
    "        \"SGD\": optimizers.SGD,\n",
    "        \"RMSprop\": optimizers.RMSprop,\n",
    "        \"Nadam\": optimizers.Nadam,\n",
    "        \"Lion\": optimizers.Lion,\n",
    "    }\n",
    "\n",
    "    # Raise error if selected optimizer is not supported in the current context\n",
    "    if optimizer_name not in optimizer_map:\n",
    "        raise ValueError(\n",
    "            f\"Optimizer '{optimizer_name}' is not supported. \"\n",
    "            f\"Supported optimizers are: {list(optimizer_map.keys())}.\"\n",
    "        )\n",
    "\n",
    "    # Instantiate and return the selected optimizer with suggested learning rate\n",
    "    return optimizer_map[optimizer_name](learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4. Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_callbacks(trial: optuna.Trial, checkpoint_dir: str) -> List[tf.keras.callbacks.Callback]:\n",
    "    \"\"\"\n",
    "    Constructs and returns a list of Keras callbacks tailored for Optuna trials.\n",
    "\n",
    "    Args:\n",
    "        trial (optuna.Trial): The current Optuna trial object.\n",
    "        checkpoint_dir (str): Directory where model weights will be saved.\n",
    "\n",
    "    Returns:\n",
    "        List[tf.keras.callbacks.Callback]: A list of callbacks to pass into `model.fit()`.\n",
    "    \"\"\"\n",
    "    # Construct path for saving weights for this specific trial\n",
    "    checkpoint_path: str = os.path.join(checkpoint_dir, f\"trial_{trial.number}.weights.h5\")\n",
    "\n",
    "    # Metric to monitor for early stopping and checkpointing\n",
    "    monitor: str = \"val_loss\"\n",
    "\n",
    "    # Stop training early if no improvement in validation loss for N epochs\n",
    "    early_stopping = callbacks.EarlyStopping(\n",
    "        monitor=monitor,\n",
    "        patience=6,  # number of epochs to wait\n",
    "        restore_best_weights=True,\n",
    "        verbose=1,\n",
    "    )\n",
    "\n",
    "    # Reduce learning rate if validation loss plateaus\n",
    "    reduce_lr = callbacks.ReduceLROnPlateau(\n",
    "        monitor=monitor,\n",
    "        patience=3,  # how many epochs to wait before reducing LR\n",
    "        factor=0.2,  # reduce LR by this factor\n",
    "        min_lr=1e-6,  # don't reduce below this\n",
    "        verbose=1,\n",
    "    )\n",
    "\n",
    "    # Save only the best model weights based on monitored metric\n",
    "    model_checkpoint = callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_path,\n",
    "        monitor=monitor,\n",
    "        save_best_only=True,  # only save weights if val_loss improves\n",
    "        save_weights_only=True,  # save only the weights (not full model)\n",
    "        verbose=0,\n",
    "    )\n",
    "\n",
    "    #! ——————— WARNING: the callbacks below do not work with multi-objective —————— !#\n",
    "    # Custom callback to prune trial if NaN loss is encountered\n",
    "    nan_pruner_callback = NanLossPrunerCallback(trial)\n",
    "\n",
    "    # Optuna's built-in pruning callback for early trial termination\n",
    "    pruning_callback = KerasPruningCallback(trial, monitor)\n",
    "    #! ———————————————————————————————————————————————————————————————————————————— !#\n",
    "\n",
    "    # Return the complete list of callbacks\n",
    "    return [early_stopping, reduce_lr, model_checkpoint, nan_pruner_callback, pruning_callback]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5. Scalers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scaler(\n",
    "    trial: optuna.Trial,\n",
    ") -> Union[StandardScaler, MinMaxScaler, RobustScaler, QuantileTransformer, PowerTransformer]:\n",
    "    \"\"\"\n",
    "    Suggests and returns a scikit-learn scaler based on Optuna hyperparameter selection.\n",
    "\n",
    "    Args:\n",
    "        trial (optuna.Trial): Optuna trial object used to suggest hyperparameters.\n",
    "\n",
    "    Returns:\n",
    "        Union[StandardScaler, MinMaxScaler, RobustScaler, QuantileTransformer, PowerTransformer]:\n",
    "            Instantiated scaler object from scikit-learn.\n",
    "    \"\"\"\n",
    "    # Suggest a scaler name from the list of supported options\n",
    "    scaler_name = trial.suggest_categorical(\n",
    "        \"scaler\",\n",
    "        [\n",
    "            \"StandardScaler\",  # For normally-distributed data\n",
    "            \"MinMaxScaler_-1_1\",  # Normalize to [-1, 1] range\n",
    "            \"MinMaxScaler_0_1\",  # Normalize to [0, 1] range\n",
    "            # \"RobustScaler\",  # For data with outliers\n",
    "            # \"QuantileTransformer\",  # For non-normal or skewed data\n",
    "            # \"PowerTransformer\",  # For heavy-tailed or skewed data\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # Return the appropriate scaler instance based on selection\n",
    "    if scaler_name == \"StandardScaler\":\n",
    "        return StandardScaler()\n",
    "    elif scaler_name == \"RobustScaler\":\n",
    "        return RobustScaler()\n",
    "    elif scaler_name == \"QuantileTransformer\":\n",
    "        return QuantileTransformer(output_distribution=\"normal\")\n",
    "    elif scaler_name == \"PowerTransformer\":\n",
    "        return PowerTransformer(method=\"yeo-johnson\")\n",
    "    elif scaler_name == \"MinMaxScaler_0_1\":\n",
    "        return MinMaxScaler(feature_range=(0, 1))\n",
    "    elif scaler_name == \"MinMaxScaler_-1_1\":\n",
    "        return MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "    # Catch invalid or unknown choices\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown scaler selected: {scaler_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6. Implementation getters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_observed_ports(sinr_data, num_observed_ports, total_ports):\n",
    "    \"\"\"\n",
    "    Extracts SINR values for the specified number of observed ports.\n",
    "\n",
    "    The function selects a subset of SINR data by identifying equally spaced ports based on the\n",
    "    number of observed ports specified. It returns the SINR values for these observed ports and\n",
    "    their corresponding indices.\n",
    "\n",
    "    Args:\n",
    "        sinr_data (numpy.ndarray): A 2D array where each row represents an observation and each column\n",
    "                                   represents a port with its corresponding SINR values.\n",
    "        num_observed_ports (int): The number of observed ports to select from the SINR data.\n",
    "        total_ports (int): The total number of ports in the SINR data.\n",
    "\n",
    "    Returns:\n",
    "        observed_sinr (numpy.ndarray): A 2D array containing the SINR values for the observed ports.\n",
    "        observed_indices (numpy.ndarray): A 1D array of the indices corresponding to the observed ports.\n",
    "    \"\"\"\n",
    "    observed_indices = np.linspace(0, total_ports - 1, num_observed_ports, dtype=int)\n",
    "    observed_sinr = sinr_data[:, observed_indices]\n",
    "\n",
    "    return observed_sinr, observed_indices\n",
    "\n",
    "\n",
    "def getOP(\n",
    "    observed_indices: np.ndarray, \n",
    "    predicted_values: np.ndarray, \n",
    "    true_values: np.ndarray, \n",
    "    threshold: float, \n",
    "    snr_linear: float,\n",
    "    total_ports: int\n",
    ") -> float:\n",
    "    \"\"\"Estimate the outage probability for regression models.\n",
    "\n",
    "    This function compares the predicted and observed signal values at different \n",
    "    channels (ports) and determines whether the chosen signal is above a given threshold. \n",
    "    The outage probability is then computed as the proportion of times the signal falls \n",
    "    below this threshold.\n",
    "\n",
    "    Args:\n",
    "        observed_indices (np.ndarray): Indices of the observed ports (channels).\n",
    "        predicted_values (np.ndarray): Matrix of predicted values for each sample.\n",
    "        true_values (np.ndarray): Ground-truth values for each port.\n",
    "        threshold (float): Threshold value for determining outage.\n",
    "        snr_linear (float): Signal-to-noise ratio in linear scale.\n",
    "\n",
    "    Returns:\n",
    "        float: Estimated outage probability.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize an array with negative infinity to store the observed values\n",
    "    observed_values_matrix = np.full((true_values.shape[0], total_ports), -np.inf, dtype=np.float64)\n",
    "\n",
    "    # Assign the true values of the observed ports (channels) to the matrix\n",
    "    observed_values_matrix[:, observed_indices] = true_values[:, observed_indices]\n",
    "\n",
    "    # Find the index of the highest predicted value for each sample\n",
    "    best_predicted_indices = np.argmax(predicted_values, axis=1)\n",
    "\n",
    "    # Initialize an array with negative infinity to store the predicted values\n",
    "    predicted_values_matrix = np.full((true_values.shape[0], total_ports), -np.inf, dtype=np.float64)\n",
    "\n",
    "    # Assign the true value corresponding to the predicted best port\n",
    "    predicted_values_matrix[np.arange(len(best_predicted_indices)), best_predicted_indices] = (\n",
    "        true_values[np.arange(len(best_predicted_indices)), best_predicted_indices]\n",
    "    )\n",
    "\n",
    "    # Take the element-wise maximum between the observed and predicted value matrices\n",
    "    best_value_matrix = np.maximum(observed_values_matrix, predicted_values_matrix)\n",
    "\n",
    "    # print(\"Shape of Best Value Matrix:\", best_value_matrix.shape)\n",
    "\n",
    "    # Find the index of the best predicted or observed port (channel) for each sample\n",
    "    best_predicted_or_observed_ports = np.argmax(best_value_matrix, axis=1)\n",
    "\n",
    "    # print(\"Shape of Best Predicted/Observed Ports:\", best_predicted_or_observed_ports.shape)\n",
    "    # print(\"Number of Selected Ports:\", len(best_predicted_or_observed_ports))\n",
    "\n",
    "    # Retrieve the actual values corresponding to the best selected ports\n",
    "    selected_values = best_value_matrix[np.arange(len(true_values)), best_predicted_or_observed_ports]\n",
    "\n",
    "    # print(\"Shape of Selected Values:\", selected_values.shape)\n",
    "\n",
    "    # Determine which selected values are above the given threshold\n",
    "    above_threshold = selected_values > (threshold / snr_linear)\n",
    "\n",
    "    # print(\"Shape of Above Threshold Array:\", above_threshold.shape)\n",
    "\n",
    "    # Compute the outage probability: probability that the selected value is below the threshold\n",
    "    outage_probability = 1.0 - (np.sum(above_threshold) / len(true_values))\n",
    "\n",
    "    return outage_probability\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Layers Builders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1. CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn1d(\n",
    "    trial: optuna.Trial,\n",
    "    x: layers.Layer,\n",
    "    num_layers: int = 5,\n",
    "    max_filters: int = 256,\n",
    "    min_filters: int = 32,\n",
    "    filter_step: int = 32,\n",
    "    max_kernel_size: int = 10,\n",
    "    min_pool_size: int = 2,\n",
    "    max_pool_size: int = 2,\n",
    "    use_batch_norm: bool = False,\n",
    "    use_regularization: bool = False,\n",
    "    residual_method: Optional[str] = None,\n",
    "    custom_name: str = \"cnn1d\",\n",
    ") -> layers.Layer:\n",
    "    \"\"\"\n",
    "    Builds a 1D CNN where Optuna picks filters, kernel sizes, and pooling window per layer.\n",
    "\n",
    "    Args:\n",
    "        trial (optuna.Trial): Optuna trial object.\n",
    "        x (Layer): Input Keras tensor.\n",
    "        num_layers (int): Number of Conv1D + Pool1D blocks.\n",
    "        max_filters (int): Upper bound on number of filters.\n",
    "        min_filters (int): Lower bound on number of filters.\n",
    "        filter_step (int): Step size when sampling number of filters.\n",
    "        max_kernel_size (int): Maximum size of the 1D convolution kernel.\n",
    "        min_pool_size (int): Minimum size of the 1D pooling window.\n",
    "        max_pool_size (int): Maximum size of the 1D pooling window.\n",
    "        use_batch_norm (bool): If True, trial may enable BatchNormalization per layer.\n",
    "        use_regularization (bool): If True, trial picks kernel, bias, and activity regularizers.\n",
    "        residual_method (Optional[str]): One of {None, \"beside\", \"all\"} to control skip connections.\n",
    "        custom_name (str): Prefix for naming all layers.\n",
    "\n",
    "    Returns:\n",
    "        Layer: Output tensor after applying all CNN blocks.\n",
    "    \"\"\"\n",
    "\n",
    "    # Placeholders for residual connection strategies\n",
    "    beside_residual: Optional[layers.Layer] = None\n",
    "    all_skip_connections: List[layers.Layer] = []\n",
    "\n",
    "    for layer_idx in range(num_layers):\n",
    "        # 1) Sample pooling window size\n",
    "        pool_size = trial.suggest_int(\n",
    "            f\"{custom_name}_pool_size_{layer_idx}\", min_pool_size, max_pool_size\n",
    "        )\n",
    "\n",
    "        # 2) Sample number of filters\n",
    "        num_filters = trial.suggest_int(\n",
    "            f\"{custom_name}_filters_{layer_idx}\",\n",
    "            min_filters,\n",
    "            max_filters,\n",
    "            step=filter_step,\n",
    "        )\n",
    "\n",
    "        # 3) Sample convolution kernel size\n",
    "        kernel_size = trial.suggest_int(\n",
    "            f\"{custom_name}_kernel_size_{layer_idx}\", 1, max_kernel_size\n",
    "        )\n",
    "\n",
    "        # 4) Activation function\n",
    "        activation_fn = get_activation(trial, f\"{custom_name}_activation_{layer_idx}\")\n",
    "\n",
    "        # 5) Regularizers (if enabled)\n",
    "        kernel_reg = (\n",
    "            get_regularizer(trial, f\"{custom_name}_kernel_regularizer_{layer_idx}\")\n",
    "            if use_regularization\n",
    "            else None\n",
    "        )\n",
    "        bias_reg = (\n",
    "            get_regularizer(trial, f\"{custom_name}_bias_regularizer_{layer_idx}\")\n",
    "            if use_regularization\n",
    "            else None\n",
    "        )\n",
    "        activity_reg = (\n",
    "            get_regularizer(trial, f\"{custom_name}_activity_regularizer_{layer_idx}\")\n",
    "            if use_regularization\n",
    "            else None\n",
    "        )\n",
    "\n",
    "        # 6) 1D convolution\n",
    "        x = layers.Conv1D(\n",
    "            filters=num_filters,\n",
    "            kernel_size=kernel_size,\n",
    "            activation=activation_fn,\n",
    "            padding=\"same\",\n",
    "            name=f\"{custom_name}_conv1d_{layer_idx}\",\n",
    "            kernel_regularizer=kernel_reg,\n",
    "            bias_regularizer=bias_reg,\n",
    "            activity_regularizer=activity_reg,\n",
    "        )(x)\n",
    "\n",
    "        # 7) Optional BatchNormalization\n",
    "        if use_batch_norm and trial.suggest_categorical(\n",
    "            f\"{custom_name}_use_batch_norm_{layer_idx}\", [True, False]\n",
    "        ):\n",
    "            x = layers.BatchNormalization(name=f\"{custom_name}_batch_norm_{layer_idx}\")(x)\n",
    "\n",
    "        # 8) Residual connections\n",
    "        if residual_method == \"beside\":\n",
    "            if layer_idx == 0:\n",
    "                beside_residual = x\n",
    "            else:\n",
    "                if trial.suggest_categorical(\n",
    "                    f\"{custom_name}_use_residual_{layer_idx}\", [True, False]\n",
    "                ):\n",
    "                    prev = beside_residual\n",
    "                    target_ch = x.shape[-1]\n",
    "                    # Align channel dimensions if needed\n",
    "                    if prev.shape[-1] != target_ch:\n",
    "                        prev = layers.Conv1D(\n",
    "                            filters=target_ch,\n",
    "                            kernel_size=1,\n",
    "                            padding=\"same\",\n",
    "                            name=f\"{custom_name}_res_align_{layer_idx}\",\n",
    "                        )(prev)\n",
    "                    x = layers.Add(name=f\"{custom_name}_res_add_{layer_idx}\")([x, prev])\n",
    "                    beside_residual = x\n",
    "                else:\n",
    "                    beside_residual = x\n",
    "\n",
    "        elif residual_method == \"all\":\n",
    "            if layer_idx == 0:\n",
    "                all_skip_connections = [x]\n",
    "            else:\n",
    "                to_add: List[layers.Layer] = []\n",
    "                for prev_idx, prev_layer in enumerate(all_skip_connections):\n",
    "                    if trial.suggest_categorical(\n",
    "                        f\"{custom_name}_use_residual_{layer_idx}_{prev_idx}\", [True, False]\n",
    "                    ):\n",
    "                        prev = prev_layer\n",
    "                        target_ch = x.shape[-1]\n",
    "                        if prev.shape[-1] != target_ch:\n",
    "                            prev = layers.Conv1D(\n",
    "                                filters=target_ch,\n",
    "                                kernel_size=1,\n",
    "                                padding=\"same\",\n",
    "                                name=f\"{custom_name}_skip_res_conv1d_{layer_idx}_{prev_idx}\",\n",
    "                            )(prev)\n",
    "                        to_add.append(prev)\n",
    "                if to_add:\n",
    "                    x = layers.Add(\n",
    "                        name=f\"{custom_name}_res_all_add_{layer_idx}\"\n",
    "                    )([x] + to_add)\n",
    "                all_skip_connections.append(x)\n",
    "\n",
    "        # 9) 1D MaxPooling\n",
    "        x = layers.MaxPooling1D(\n",
    "            pool_size=pool_size, name=f\"{custom_name}_maxpool_{layer_idx}\"\n",
    "        )(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Objective Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(\n",
    "    trial: optuna.Trial,\n",
    "    X: List[np.ndarray],\n",
    "    y: List[np.ndarray],\n",
    "    checkpoint_dir: str,\n",
    "    model_dir: str,\n",
    "    fig_dir: str,\n",
    "    logs_dir: str,\n",
    "    epochs: int = 50,\n",
    "    size_penalizer: Optional[str] = None,\n",
    "    use_regularization: bool = False,\n",
    "    residual_method: Optional[str] = None,\n",
    "    show_summary: bool = False,\n",
    "    plot_model: bool = False,\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Objective function for Optuna to optimize a Neural Network NN on any-input data.\n",
    "\n",
    "    Args:\n",
    "        trial (optuna.Trial): Current trial for hyperparameter suggestions.\n",
    "        X (List[np.ndarray]): List of input arrays.\n",
    "        y (List[np.ndarray]): List of label arrays.\n",
    "        checkpoint_dir (str): Path to store checkpoint files.\n",
    "        model_dir (str): Path to store full models.\n",
    "        fig_dir (str): Path to store plots.\n",
    "        logs_dir (str): Path to store logs.\n",
    "        epochs (int): Number of training epochs.\n",
    "        size_penalizer (Optional[str]): type of penalizer to use:\n",
    "            - \"params\": Penalizes based on the number of parameters.\n",
    "            - \"flops\": Penalizes based on the number of FLOPs.\n",
    "            - None: No penalization is applied.\n",
    "        use_regularization (bool): If True, adds regularization (e.g., L1/L2) to layers to prevent overfitting.\n",
    "        residual_method (Optional[str]): tyoe of residual connection to use:\n",
    "            - \"beside\": Adds residual connections between consecutive layers.\n",
    "            - \"all\": test residual connections between all layers.\n",
    "            - None: No residual connections are applied.\n",
    "        show_summary (bool): If True, display the model summary.\n",
    "        plot_model (bool): If True, display a plot of the model architecture.\n",
    "\n",
    "    Returns:\n",
    "        float: Final validation loss (optionally penalized) used for optimization.\n",
    "    \"\"\"\n",
    "    \n",
    "    # ————————————————————————————— Prepare the Data ————————————————————————————— #\n",
    "    X_train, X_val = X[0], X[1]\n",
    "    y_train, y_val = y[0], y[1]\n",
    "\n",
    "    # ———————————————————————————————————————————————————————————————————————————— #\n",
    "\n",
    "    model = None\n",
    "    try:\n",
    "\n",
    "        # ———————————————————————————————————————————————————————————————————————————— #\n",
    "        #                              Model Construction                              #\n",
    "        # ———————————————————————————————————————————————————————————————————————————— #\n",
    "\n",
    "        # —————————————————————————————————— Scaler —————————————————————————————————— #\n",
    "        scaler = get_scaler(trial)\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_val = scaler.transform(X_val)\n",
    "        \n",
    "        # ———————————————————————————— Reshape for 1D CNN ———————————————————————————— #\n",
    "        # (num_samples, observed_ports) -> (num_samples, observed_ports, 1)\n",
    "        X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "        X_val = X_val.reshape(X_val.shape[0], X_val.shape[1], 1)\n",
    "\n",
    "        # ——————————————————————————— Observed ports input ——————————————————————————— #\n",
    "        inputs = layers.Input(shape=(X_train.shape[1], 1))  # Observed ports as input\n",
    "\n",
    "        max_layers = trial.suggest_int(\"num_layers\", 1, 4)\n",
    "\n",
    "        # Calculate max pool size\n",
    "        max_pool_dim1 = math.floor(X_train.shape[1] ** (1.0 / max_layers))\n",
    "\n",
    "        x = build_cnn1d(\n",
    "            trial,\n",
    "            inputs,\n",
    "            num_layers=max_layers,\n",
    "            max_filters=512,\n",
    "            min_filters=32,\n",
    "            filter_step=32,\n",
    "            max_kernel_size=5,\n",
    "            min_pool_size=1,\n",
    "            max_pool_size=max_pool_dim1,\n",
    "            use_batch_norm=True,\n",
    "            use_regularization=use_regularization,\n",
    "            residual_method=residual_method,\n",
    "        )\n",
    "\n",
    "        # ———————————————————————————— Flatten the Output ———————————————————————————— #\n",
    "        x = layers.Flatten(name=\"flatten\")(x)\n",
    "\n",
    "        # ——————————————————————————————— Dense Layers ——————————————————————————————— #\n",
    "        #? This was the best performing option in the previous trials\n",
    "        num_dense_layers = trial.suggest_int(\"num_dense_layers\", 0, 3)\n",
    "        for i in range(num_dense_layers):\n",
    "            # Suggest the number of units for each dense layer\n",
    "            units = trial.suggest_int(f\"dense_{i+1}_units\", 64, 512, step=64)\n",
    "            x = layers.Dense(\n",
    "                units=units,\n",
    "                activation=get_activation(trial, f\"dense_{i+1}_activation\"),\n",
    "                name=f\"dense_{i+1}\",\n",
    "            )(x)\n",
    "            rate = trial.suggest_float(f\"dense_{i+1}_dropout\", 0.0, 0.5, step=0.1)\n",
    "            x = layers.Dropout(rate=rate)(x)\n",
    "\n",
    "        # —————————————————————————————————— Output —————————————————————————————————— #\n",
    "        outputs = layers.Dense(TOTAL_NUM_PORTS, activation=\"linear\")(x)\n",
    "\n",
    "        # —————————————————————————— Set Inputs and Outputs —————————————————————————— #\n",
    "        model = Model(inputs=inputs, outputs=(outputs,))\n",
    "\n",
    "        # ———————————————————————————— Vizualize the Model ——————————————————————————— #\n",
    "        if show_summary:\n",
    "            model.summary()\n",
    "\n",
    "        if plot_model:\n",
    "            # Display the model architecture image\n",
    "            tf.keras.utils.plot_model(\n",
    "                model,\n",
    "                to_file=os.path.join(fig_dir, f\"model_plot_{trial.number}.png\"),\n",
    "                show_shapes=True,\n",
    "                show_layer_names=True,\n",
    "            )\n",
    "            display(Image(filename=os.path.join(fig_dir, f\"model_plot_{trial.number}.png\")))\n",
    "\n",
    "        # ————————————————————————————— Compile the Model ———————————————————————————— #\n",
    "        optimizer = get_optimizer(trial)\n",
    "        model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss=\"mse\",\n",
    "        )\n",
    "\n",
    "        # ———————————————————————————————— Train Model ——————————————————————————————— #\n",
    "        batch_size = trial.suggest_categorical(\"batch_size\", [64, 128, 256])\n",
    "        history = model.fit(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            callbacks=get_callbacks(trial, checkpoint_dir),\n",
    "            verbose=2,\n",
    "        )\n",
    "\n",
    "        model.save(os.path.join(model_dir, f\"trial_{trial.number}.keras\"))\n",
    "        loss = min(history.history[\"val_loss\"])\n",
    "\n",
    "        # ———————————————————————————————————————————————————————————————————————————— #\n",
    "        #                                 Trial Results                                #\n",
    "        # ———————————————————————————————————————————————————————————————————————————— #\n",
    "        clear_output(wait=True)\n",
    "\n",
    "        epochs = list(range(1, len(history.history[\"loss\"]) + 1))\n",
    "        train_loss = history.history[\"loss\"]\n",
    "        val_loss = history.history[\"val_loss\"]\n",
    "    \n",
    "        # Create figure\n",
    "        fig, ax_loss = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "        # Plot Loss\n",
    "        ax_loss.plot(epochs, train_loss, marker=\"o\", linestyle=\"-\", label=\"Training Loss\")\n",
    "        ax_loss.plot(epochs, val_loss, marker=\"x\", linestyle=\"--\", label=\"Validation Loss\")\n",
    "        ax_loss.set_title(\"Training & Validation Loss\")\n",
    "        ax_loss.set_xlabel(\"Epoch\")\n",
    "        ax_loss.set_ylabel(\"Loss\")\n",
    "        ax_loss.set_xticks(epochs)\n",
    "        ax_loss.set_ylim(0, max(max(train_loss), max(val_loss)) * 1.05)\n",
    "        ax_loss.grid(True)\n",
    "        ax_loss.legend()\n",
    "\n",
    "        fig.tight_layout()\n",
    "        fig.savefig(os.path.join(fig_dir, f\"trial_{trial.number}.png\"), dpi=300)\n",
    "        plt.close(fig)\n",
    "\n",
    "        # ————————————————————————————————— Evaluate ————————————————————————————————— #\n",
    "        datasets = [\n",
    "            kappa0_mu1_m0_test,\n",
    "            kappa0_mu1_m2_test,\n",
    "            kappa0_mu1_m50_test,\n",
    "            kappa0_mu2_m50_test,\n",
    "            kappa0_mu5_m50_test,\n",
    "            kappa5_mu1_m0_test,\n",
    "            kappa5_mu1_m2_test,\n",
    "            kappa5_mu1_m50_test,\n",
    "            kappa5_mu2_m0_test,\n",
    "            kappa5_mu2_m2_test,\n",
    "            kappa5_mu2_m50_test,\n",
    "            kappa5_mu5_m0_test,\n",
    "            kappa5_mu5_m2_test,\n",
    "            kappa5_mu5_m50_test,\n",
    "        ]\n",
    "        test_losses = []\n",
    "        ops = []\n",
    "\n",
    "        n_ports = X_train.shape[1]\n",
    "\n",
    "        for i, dataset in enumerate(datasets, start=1):\n",
    "            observed_ports, observed_indices = get_observed_ports(\n",
    "                dataset, num_observed_ports=n_ports, total_ports=TOTAL_NUM_PORTS\n",
    "            )\n",
    "            \n",
    "            X_test, y_test = observed_ports, dataset\n",
    "            X_test = scaler.transform(X_test)\n",
    "            \n",
    "            # Reshape for 1D CNN\n",
    "            X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "            \n",
    "            test_loss = model.evaluate(X_test, y_test, batch_size=batch_size, verbose=0)\n",
    "            test_losses.append(test_loss)\n",
    "            \n",
    "            # Make predictions\n",
    "            y_pred = model.predict(X_test)\n",
    "\n",
    "            # Calculate Outage Probability (OP)\n",
    "            op_value = getOP(\n",
    "                observed_indices=observed_indices,\n",
    "                predicted_values=y_pred,\n",
    "                true_values=y_test,\n",
    "                threshold=THRESHOLD,\n",
    "                snr_linear=SNR_LINEAR,\n",
    "                total_ports=TOTAL_NUM_PORTS,\n",
    "            )\n",
    "            ops.append(op_value)\n",
    "\n",
    "        dataset_names: list[str] = [\n",
    "            \"kappa0_mu1_m0_test\",\n",
    "            \"kappa0_mu1_m2_test\",\n",
    "            \"kappa0_mu1_m50_test\",\n",
    "            \"kappa0_mu2_m50_test\",\n",
    "            \"kappa0_mu5_m50_test\",\n",
    "            \"kappa5_mu1_m0_test\",\n",
    "            \"kappa5_mu1_m2_test\",\n",
    "            \"kappa5_mu1_m50_test\",\n",
    "            \"kappa5_mu2_m0_test\",\n",
    "            \"kappa5_mu2_m2_test\",\n",
    "            \"kappa5_mu2_m50_test\",\n",
    "            \"kappa5_mu5_m0_test\",\n",
    "            \"kappa5_mu5_m2_test\",\n",
    "            \"kappa5_mu5_m50_test\",\n",
    "        ]\n",
    "\n",
    "        dataset_test_losses = {\n",
    "            f\"{name}_loss\": loss\n",
    "            for name, loss in zip(dataset_names, test_losses)\n",
    "        }\n",
    "        dataset_test_ops = {\n",
    "            f\"{name}_op\": op\n",
    "            for name, op in zip(dataset_names, ops)\n",
    "        }\n",
    "\n",
    "        # Print test losses in a formatted manner\n",
    "        print(\"\\n\" + \"=\" * 15)\n",
    "        for name in dataset_names:\n",
    "            loss = dataset_test_losses[f\"{name}_loss\"]\n",
    "            op   = dataset_test_ops[f\"{name}_op\"]\n",
    "            print(\n",
    "                f\"{name.replace('_', ' ').capitalize()}: \"\n",
    "                f\"Loss = {loss:.12f}, OP = {op:.12f}\"\n",
    "            )\n",
    "            \n",
    "\n",
    "        params = model.count_params()\n",
    "        print(f\"\\nNumber of parameters: {params}\")\n",
    "        print(f\"Model size: {params * 4 / (1024 ** 2):.2f} MB\")\n",
    "        print(\"=\" * 15 + \"\\n\")\n",
    "        \n",
    "        trial.set_user_attr(\"num_params\", params)\n",
    "        trial.set_user_attr(\"model_size_mb\", params * 4 / (1024 ** 2))\n",
    "\n",
    "        return loss\n",
    "\n",
    "    except optuna.exceptions.TrialPruned:\n",
    "        raise  # simply propagate pruning\n",
    "    except tf.errors.ResourceExhaustedError as oom_err:\n",
    "        # Catch OOM / resource exhausted\n",
    "        print(f\"❌ Trial {trial.number} hit OOM (ResourceExhaustedError): {oom_err}\")\n",
    "\n",
    "        # Log the error to a file in the logs directory\n",
    "        error_log_path = os.path.join(logs_dir, f\"trial_{trial.number}_error.log\")\n",
    "        with open(error_log_path, \"w\") as log_file:\n",
    "            log_file.write(f\"Trial {trial.number} encountered an error:\\n\")\n",
    "            log_file.write(str(oom_err) + \"\\n\\n\")\n",
    "            log_file.write(\"Traceback:\\n\")\n",
    "            traceback.print_exc(file=log_file)\n",
    "\n",
    "        return float(\"inf\")  # Return bad loss\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during the trial execution: {e}\")\n",
    "        traceback.print_exc()\n",
    "\n",
    "        # Log the error to a file in the logs directory\n",
    "        error_log_path = os.path.join(logs_dir, f\"trial_{trial.number}_error.log\")\n",
    "        with open(error_log_path, \"w\") as log_file:\n",
    "            log_file.write(f\"Trial {trial.number} encountered an error:\\n\")\n",
    "            log_file.write(str(e) + \"\\n\\n\")\n",
    "            log_file.write(\"Traceback:\\n\")\n",
    "            traceback.print_exc(file=log_file)\n",
    "\n",
    "        return float(\"inf\")  # Return bad loss\n",
    "    finally:\n",
    "        if model is not None:\n",
    "            clear_session()\n",
    "            del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Code Health Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resources_dir = os.path.join(RUN_DIR, \"resources\")\n",
    "# os.makedirs(resources_dir, exist_ok=True)\n",
    "# troo.log_resources(log_dir=resources_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    pid = os.getpid()\n",
    "    cmd = (\n",
    "        f'python3 \"{os.path.abspath(\"_monitor_kernel_life.py\")}\" '\n",
    "        f\"--pid {pid} --custom-title {RUN_DIR}; exec bash\"\n",
    "    )\n",
    "    terminals = [\n",
    "        [\"xfce4-terminal\", \"--disable-server\", \"--hold\", \"-e\", f'bash -c \"{cmd}\"'],\n",
    "        [\"gnome-terminal\", \"--disable-factory\", \"--\", \"bash\", \"-i\", \"-c\", cmd],\n",
    "        [\"xterm\", \"-hold\", \"-e\", cmd],\n",
    "        [\"konsole\", \"--hold\", \"-e\", f'bash -c \"{cmd}\"'],\n",
    "    ]\n",
    "    term = next((t for t in terminals if shutil.which(t[0])), None)\n",
    "    if not term:\n",
    "        raise RuntimeError(\n",
    "            \"No supported terminal emulator found; install gnome-terminal, \"\n",
    "            \"xfce4-terminal, konsole, or xterm.\"\n",
    "        )\n",
    "    _monitor_proc = subprocess.Popen(term, preexec_fn=os.setpgrp)\n",
    "    print(f\"[INFO] Launched monitor in {term[0]} (PID={pid})\")\n",
    "except Exception as e:\n",
    "    print(f\"[ERROR] Auto launching kernel monitoring failed! {e}\\n\")\n",
    "    display(\n",
    "        HTML(\n",
    "            f\"Call the monitor script manually: \"\n",
    "            f'<span style=\"color: orange;\">'\n",
    "            f\"python _monitor_kernel_life.py --pid {pid} --custom-title {RUN_DIR}\"\n",
    "            f\"</span>\"\n",
    "        )\n",
    "    )\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in observed_ports_list:\n",
    "    try:\n",
    "        # ——————————————————————————————— Storage paths —————————————————————————————— #\n",
    "        study_dir = os.path.join(RUN_DIR, f\"optuna_study_{n}_ports\")\n",
    "        os.makedirs(study_dir, exist_ok=True)\n",
    "\n",
    "        dirs = {\n",
    "            \"args\": os.path.join(study_dir, \"args\"),\n",
    "            \"figures\": os.path.join(study_dir, \"figures\"),\n",
    "            \"weights\": os.path.join(study_dir, \"weights\"),\n",
    "            \"models\": os.path.join(study_dir, \"models\"),\n",
    "            \"logs\": os.path.join(study_dir, \"logs\"),\n",
    "        }\n",
    "        for path in dirs.values():\n",
    "            os.makedirs(path, exist_ok=True)\n",
    "\n",
    "        storage_path = f\"sqlite:///{os.path.join(study_dir, 'optuna_study.db')}\"\n",
    "        checkpoint_dir, model_dir, fig_dir, args_dir, logs_dir = (\n",
    "            dirs[\"weights\"],\n",
    "            dirs[\"models\"],\n",
    "            dirs[\"figures\"],\n",
    "            dirs[\"args\"],\n",
    "            dirs[\"logs\"],\n",
    "        )\n",
    "\n",
    "        print(f\"Initializing study at '{study_dir}'...\")\n",
    "        \n",
    "        # ——————————————————————————————————— Data ——————————————————————————————————— #\n",
    "        observed_ports, observed_indices = get_observed_ports(\n",
    "            dataset, num_observed_ports=n, total_ports=TOTAL_NUM_PORTS\n",
    "        )\n",
    "        \n",
    "        # split the dataset into training and validation sets\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            observed_ports,\n",
    "            dataset,\n",
    "            test_size=0.2,\n",
    "            random_state=0,\n",
    "            shuffle=True,\n",
    "        )\n",
    "            \n",
    "        # —————————————————————————————————— Pruners ————————————————————————————————— #\n",
    "        pruner = optuna.pruners.HyperbandPruner()\n",
    "\n",
    "        # ——————————————————————————————————— Study —————————————————————————————————— #\n",
    "        study = optuna.create_study(\n",
    "            study_name=os.path.basename(study_dir),\n",
    "            storage=storage_path,\n",
    "            direction=\"minimize\",\n",
    "            pruner=pruner,\n",
    "            load_if_exists=True,\n",
    "        )\n",
    "\n",
    "        # Count trials done, then determine the remaining trials\n",
    "        done_trials = len(\n",
    "            study.get_trials(\n",
    "                deepcopy=False,\n",
    "                states=(\n",
    "                    optuna.trial.TrialState.COMPLETE,\n",
    "                    optuna.trial.TrialState.PRUNED,\n",
    "                    optuna.trial.TrialState.FAIL,\n",
    "                ),\n",
    "            )\n",
    "        )\n",
    "        n_remaining_trials = max(0, NUM_TRIALS - done_trials)\n",
    "\n",
    "        study.optimize(\n",
    "            lambda trial: objective(\n",
    "                trial,\n",
    "                X=[X_train, X_val],\n",
    "                y=[y_train, y_val],\n",
    "                checkpoint_dir=checkpoint_dir,\n",
    "                model_dir=model_dir,\n",
    "                fig_dir=fig_dir,\n",
    "                logs_dir=logs_dir,\n",
    "                epochs=EPOCHS,\n",
    "                size_penalizer=None,\n",
    "                use_regularization=False,\n",
    "                residual_method=None,  #! Find your backbone first\n",
    "                show_summary=False,\n",
    "            ),\n",
    "            n_trials=n_remaining_trials,\n",
    "            catch=(ValueError, RuntimeError),\n",
    "            gc_after_trial=True,\n",
    "            n_jobs=1,  # If you have multiple GPUs/Cores\n",
    "            show_progress_bar=False,\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kill the monitor kernel life process\n",
    "if _monitor_proc is not None and _monitor_proc.poll() is None:\n",
    "    os.killpg(_monitor_proc.pid, signal.SIGINT)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-optuna",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
