{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# cGAN for FAS\n",
    "\n",
    "- **Author:** Matheus Ferreira Silva \n",
    "- **Email:** matheus.ferreira@get.inatel.br\n",
    "- **Date:** September 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 08:19:36.140668: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-10 08:19:36.182810: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-10 08:19:36.195673: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import keras\n",
    "from keras import layers\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "from tensorflow.keras.optimizers import AdamW\n",
    "from tensorflow.keras.callbacks import EarlyStopping, Callback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow is using the following GPU(s): ['/physical_device:GPU:0']\n",
      "Currently using GPU: /device:GPU:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1725967185.520417 4077036 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1725967185.590212 4077036 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1725967185.594947 4077036 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1725967185.601284 4077036 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1725967185.604702 4077036 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1725967185.607913 4077036 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1725967185.759434 4077036 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1725967185.761439 4077036 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1725967185.762943 4077036 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "# Specify which GPU to use (e.g., GPU 0)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "tf.config.optimizer.set_experimental_options({'layout_optimizer': False})\n",
    "\n",
    "# Check if TensorFlow is using the correct GPU\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(f\"TensorFlow is using the following GPU(s): {[gpu.name for gpu in gpus]}\")\n",
    "    print(f\"Currently using GPU: {tf.test.gpu_device_name()}\")\n",
    "else:\n",
    "    print(\"No GPU found. Running on CPU.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/dataset_1_frame_20k_20dB/received_samples.mat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/Matheus/Fluid-Antenna-Channel-Estimation/.venv/lib/python3.10/site-packages/scipy/io/matlab/_mio.py:39\u001b[0m, in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_like\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;66;03m# Probably \"not found\"\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/dataset_1_frame_20k_20dB/received_samples.mat'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 30\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNormalized data saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_file_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with variable name \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_var_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Normalize and save the datasets\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m \u001b[43mnormalize_mat_df\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfile_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata/dataset_1_frame_20k_20dB/received_samples.mat\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreceived_samples\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata/dataset_1_frame_20k_20dB/received_samples_normalized.mat\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnew_var_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreceived_samples_normalized\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m normalize_mat_df(\n\u001b[1;32m     38\u001b[0m     file_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/dataset_1_frame_20k_20dB/channel_history.mat\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     39\u001b[0m     var\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchannel_history\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     40\u001b[0m     output_file_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/dataset_1_frame_20k_20dB/channel_history_normalized.mat\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     41\u001b[0m     new_var_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchannel_history_normalized\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     42\u001b[0m )\n\u001b[1;32m     44\u001b[0m normalize_mat_df(\n\u001b[1;32m     45\u001b[0m     file_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/dataset_1_frame_20k_20dB/interpolated_channel.mat\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     46\u001b[0m     var\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minterpolated_channel\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     47\u001b[0m     output_file_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/dataset_1_frame_20k_20dB/interpolated_channel_normalized.mat\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     48\u001b[0m     new_var_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minterpolated_channel_normalized\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     49\u001b[0m )\n",
      "Cell \u001b[0;32mIn[3], line 19\u001b[0m, in \u001b[0;36mnormalize_mat_df\u001b[0;34m(file_path, var, output_file_path, new_var_name)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnormalize_mat_df\u001b[39m(file_path, var, output_file_path, new_var_name):\n\u001b[1;32m      5\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124;03m    Normalizes a complex dataset from a .mat file by applying normalization\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;03m    to each generation separately using the maximum absolute value for that generation.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03m        None\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43msio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloadmat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m data[var]\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;66;03m# Normalize each generation separately\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Matheus/Fluid-Antenna-Channel-Estimation/.venv/lib/python3.10/site-packages/scipy/io/matlab/_mio.py:225\u001b[0m, in \u001b[0;36mloadmat\u001b[0;34m(file_name, mdict, appendmat, **kwargs)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;124;03mLoad MATLAB file.\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;124;03m    3.14159265+3.14159265j])\u001b[39;00m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    224\u001b[0m variable_names \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvariable_names\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 225\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _open_file_context(file_name, appendmat) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    226\u001b[0m     MR, _ \u001b[38;5;241m=\u001b[39m mat_reader_factory(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    227\u001b[0m     matfile_dict \u001b[38;5;241m=\u001b[39m MR\u001b[38;5;241m.\u001b[39mget_variables(variable_names)\n",
      "File \u001b[0;32m/usr/lib/python3.10/contextlib.py:135\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Matheus/Fluid-Antenna-Channel-Estimation/.venv/lib/python3.10/site-packages/scipy/io/matlab/_mio.py:17\u001b[0m, in \u001b[0;36m_open_file_context\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;129m@contextmanager\u001b[39m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_context\u001b[39m(file_like, appendmat, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m---> 17\u001b[0m     f, opened \u001b[38;5;241m=\u001b[39m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_like\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mappendmat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     19\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m f\n",
      "File \u001b[0;32m~/Documents/Matheus/Fluid-Antenna-Channel-Estimation/.venv/lib/python3.10/site-packages/scipy/io/matlab/_mio.py:45\u001b[0m, in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m appendmat \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m file_like\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.mat\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     44\u001b[0m         file_like \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.mat\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_like\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[1;32m     48\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReader needs file name or open file-like object\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     49\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/dataset_1_frame_20k_20dB/received_samples.mat'"
     ]
    }
   ],
   "source": [
    "\n",
    "#! Change the normalization method?\n",
    "#! Normalize by mean and unit variance??\n",
    "\n",
    "def normalize_mat_df(file_path, var, output_file_path, new_var_name):\n",
    "    \"\"\"\n",
    "    Normalizes a complex dataset from a .mat file by applying normalization\n",
    "    to each generation separately using the maximum absolute value for that generation.\n",
    "    Saves the normalized dataset to a new .mat file with a different variable name.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the .mat file.\n",
    "        var (str): Variable name in the .mat file.\n",
    "        output_file_path (str): Path where the normalized .mat file will be saved.\n",
    "        new_var_name (str): New variable name for the normalized dataset in the saved .mat file.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    data = sio.loadmat(file_path)\n",
    "    dataset = data[var]\n",
    "\n",
    "    # Normalize each generation separately\n",
    "    normalized_dataset = dataset / np.max(np.abs(dataset), axis=(0, 1), keepdims=True)\n",
    "\n",
    "    sio.savemat(output_file_path, {new_var_name: normalized_dataset})\n",
    "    print(f\"Normalized data saved to {output_file_path} with variable name '{new_var_name}'\")\n",
    "\n",
    "\n",
    "# Normalize and save the datasets\n",
    "normalize_mat_df(\n",
    "    file_path=\"data/dataset_1_frame_20k_20dB/received_samples.mat\",\n",
    "    var=\"received_samples\",\n",
    "    output_file_path=\"data/dataset_1_frame_20k_20dB/received_samples_normalized.mat\",\n",
    "    new_var_name=\"received_samples_normalized\",\n",
    ")\n",
    "\n",
    "normalize_mat_df(\n",
    "    file_path=\"data/dataset_1_frame_20k_20dB/channel_history.mat\",\n",
    "    var=\"channel_history\",\n",
    "    output_file_path=\"data/dataset_1_frame_20k_20dB/channel_history_normalized.mat\",\n",
    "    new_var_name=\"channel_history_normalized\",\n",
    ")\n",
    "\n",
    "normalize_mat_df(\n",
    "    file_path=\"data/dataset_1_frame_20k_20dB/interpolated_channel.mat\",\n",
    "    var=\"interpolated_channel\",\n",
    "    output_file_path=\"data/dataset_1_frame_20k_20dB/interpolated_channel_normalized.mat\",\n",
    "    new_var_name=\"interpolated_channel_normalized\",\n",
    ")\n",
    "\n",
    "normalize_mat_df(\n",
    "    file_path=\"data/dataset_1_frame_20k_20dB/pilot_channel_estimative.mat\",\n",
    "    var=\"pilot_channel_estimative\",\n",
    "    output_file_path=\"data/dataset_1_frame_20k_20dB/pilot_channel_estimative_normalized.mat\",\n",
    "    new_var_name=\"pilot_channel_estimative_normalized\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received samples shape: (100, 1, 2, 20000)\n",
      "Pilot estimation shape: (100, 1, 2, 20000)\n",
      "Perfect channel shape: (100, 1, 2, 20000)\n",
      "Interpolated channel shape: (100, 1, 2, 20000)\n"
     ]
    }
   ],
   "source": [
    "def load_mat_df(file_path, var):\n",
    "    \"\"\"\n",
    "    Loads a complex dataset from a .mat file, separates it into real and imaginary components,\n",
    "    and returns a 4D matrix with dimensions N_Ports x Frame_size x 2 x Generations.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the .mat file.\n",
    "        var (str): Variable name in the .mat file.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: A 4D array with real and imaginary parts separated along the third dimension.\n",
    "    \"\"\"\n",
    "    data = sio.loadmat(file_path)[var]  # Load the data directly from the .mat file\n",
    "    real_part = np.real(data)  # Extract the real part\n",
    "    imag_part = np.imag(data)  # Extract the imaginary part\n",
    "    return np.stack((real_part, imag_part), axis=2)  # Combine into a 4D array\n",
    "\n",
    "\n",
    "# ------------------- Load the datasets with normalization ------------------- #\n",
    "# received_samples = load_mat_df(\n",
    "#     \"data/dataset_1_frame_20k_20dB/received_samples_normalized.mat\", \"received_samples_normalized\"\n",
    "# )\n",
    "# pilot_channel_estimative = load_mat_df(\n",
    "#     \"data/dataset_1_frame_20k_20dB/pilot_channel_estimative_normalized.mat\", \"pilot_channel_estimative_normalized\"\n",
    "# ) # This represents only x ports that were estimated using pilot symbols\n",
    "# perfect_channel = load_mat_df(\n",
    "#     \"data/dataset_1_frame_20k_20dB/channel_history_normalized.mat\", \"channel_history_normalized\"\n",
    "# ) # This is the real channel\n",
    "# interpolated_channel = load_mat_df(\n",
    "#     \"data/dataset_1_frame_20k_20dB/interpolated_channel_normalized.mat\", \"interpolated_channel_normalized\"\n",
    "# ) # The interpolated channel is used for comparison purposes\n",
    "\n",
    "# ------------------ Load the datasets without normalization ----------------- #\n",
    "received_samples = load_mat_df(\"data/dataset_1_frame_20k_20dB/received_samples.mat\", \"received_samples\")\n",
    "pilot_channel_estimative = load_mat_df(\n",
    "    \"data/dataset_1_frame_20k_20dB/pilot_channel_estimative.mat\", \"pilot_channel_estimative\"\n",
    ")  # This represents only x ports that were estimated using pilot symbols\n",
    "perfect_channel = load_mat_df(\n",
    "    \"data/dataset_1_frame_20k_20dB/channel_history.mat\", \"channel_history\"\n",
    ")  # This is the real channel\n",
    "interpolated_channel = load_mat_df(\n",
    "    \"data/dataset_1_frame_20k_20dB/interpolated_channel.mat\", \"interpolated_channel\"\n",
    ")  # The interpolated channel is used for comparison purposes\n",
    "\n",
    "# Print the shapes of the datasets, type <class 'numpy.ndarray'>\n",
    "print(f\"Received samples shape: {received_samples.shape}\")\n",
    "print(f\"Pilot estimation shape: {pilot_channel_estimative.shape}\")\n",
    "print(f\"Perfect channel shape: {perfect_channel.shape}\")\n",
    "print(f\"Interpolated channel shape: {interpolated_channel.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Input for Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pilot estimation shape: (20000, 100, 1, 2)\n",
      "Perfect channel shape: (20000, 100, 1, 2)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Transpose the data to fit the input structure (generations, ports, frame size, dimensions)\n",
    "pilot_channel_estimative = np.transpose(pilot_channel_estimative, (3, 0, 1, 2))\n",
    "perfect_channel = np.transpose(perfect_channel, (3, 0, 1, 2))\n",
    "\n",
    "print(f\"Pilot estimation shape: {pilot_channel_estimative.shape}\")\n",
    "print(f\"Perfect channel shape: {perfect_channel.shape}\")\n",
    "\n",
    "# Create tf.data.Dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices((pilot_channel_estimative, perfect_channel))\n",
    "dataset = dataset.shuffle(buffer_size=1024).batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cGAN Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50 # Number of epochs for the training\n",
    "patience = 10 # Patience for the early stopping\n",
    "num_ports = 100  # Modify this based on your data\n",
    "frame_size = 1  # Modify this based on your data\n",
    "latent_dim = 128\n",
    "dimensions = 2  # real and imaginary parts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GAN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.InputLayer((latent_dim,)),\n",
    "        layers.Dense(100 * 1 * 64),\n",
    "        layers.LeakyReLU(negative_slope=0.2),\n",
    "        layers.Reshape((100, 1, 64)),  # Corrected this line to use a tuple (100, 1, 64)\n",
    "        layers.Conv2DTranspose(64, kernel_size=(3, 1), strides=(1, 1), padding=\"same\"),\n",
    "        layers.LeakyReLU(negative_slope=0.2),\n",
    "        layers.Conv2DTranspose(32, kernel_size=(3, 1), strides=(1, 1), padding=\"same\"),\n",
    "        layers.LeakyReLU(negative_slope=0.2),\n",
    "        layers.Conv2D(2, (3, 1), padding=\"same\", activation=\"sigmoid\"),  # Output shape (100, 1, 2)\n",
    "    ],\n",
    "    name=\"generator\",\n",
    ")\n",
    "\n",
    "discriminator = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.InputLayer((100, 1, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 1), strides=(1, 1), padding=\"same\"),\n",
    "        layers.LeakyReLU(negative_slope=0.2),\n",
    "        layers.Conv2D(128, kernel_size=(3, 1), strides=(1, 1), padding=\"same\"),\n",
    "        layers.LeakyReLU(negative_slope=0.2),\n",
    "        layers.GlobalMaxPooling2D(),\n",
    "        layers.Dense(1),\n",
    "    ],\n",
    "    name=\"discriminator\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN(keras.Model):\n",
    "    \"\"\"\n",
    "    GAN (Generative Adversarial Network) class that inherits from keras.Model.\n",
    "\n",
    "    Parameters:\n",
    "    - discriminator: The discriminator model (a neural network that classifies real vs. fake images)\n",
    "    - generator: The generator model (a neural network that generates fake images from latent space)\n",
    "    - latent_dim: Dimensionality of the latent space (input noise vector for the generator)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, discriminator, generator, latent_dim):\n",
    "        \"\"\"\n",
    "        Initialize the GAN model by setting the discriminator, generator, and latent dimension.\n",
    "        Also initializes loss trackers for both generator and discriminator.\n",
    "        \"\"\"\n",
    "        super().__init__()  # Call the parent class (keras.Model) initializer\n",
    "        self.discriminator = discriminator  # Discriminator model for distinguishing real/fake images\n",
    "        self.generator = generator  # Generator model to generate fake images\n",
    "        self.latent_dim = latent_dim  # Latent dimension used to sample random points for generator\n",
    "\n",
    "        # Trackers for generator and discriminator loss\n",
    "        self.gen_loss_tracker = keras.metrics.Mean(name=\"generator_loss\")  # Mean metric for generator loss\n",
    "        self.disc_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"discriminator_loss\"\n",
    "        )  # Mean metric for discriminator loss\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        \"\"\"\n",
    "        Return the list of metrics being tracked (generator and discriminator loss).\n",
    "        This is required by keras to monitor these metrics during training.\n",
    "        \"\"\"\n",
    "        return [self.gen_loss_tracker, self.disc_loss_tracker]\n",
    "\n",
    "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
    "        \"\"\"\n",
    "        Configure the GAN model for training by setting the optimizers and loss function.\n",
    "\n",
    "        Parameters:\n",
    "        - d_optimizer: Optimizer for the discriminator (e.g., Adam)\n",
    "        - g_optimizer: Optimizer for the generator (e.g., Adam)\n",
    "        - loss_fn: Loss function to compute the loss for both generator and discriminator (e.g., binary crossentropy)\n",
    "        \"\"\"\n",
    "        super().compile()  # Call the parent class (keras.Model) compile method\n",
    "        self.d_optimizer = d_optimizer  # Optimizer for discriminator\n",
    "        self.g_optimizer = g_optimizer  # Optimizer for generator\n",
    "        self.loss_fn = loss_fn  # Loss function to compute both generator and discriminator losses\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"\"\"\n",
    "        Define the forward pass of the GAN model.\n",
    "\n",
    "        Parameters:\n",
    "        - inputs: Input data (typically noise vector for the generator).\n",
    "\n",
    "        Returns:\n",
    "        - The output of the generator (fake images).\n",
    "        \"\"\"\n",
    "        latent_vector = inputs  # Inputs should be the latent vector\n",
    "        return self.generator(latent_vector)  # Forward pass just returns the generator's output\n",
    "\n",
    "    def train_step(self, data):\n",
    "        \"\"\"\n",
    "        Perform a single training step of the GAN model, updating both the discriminator and generator.\n",
    "\n",
    "        Parameters:\n",
    "        - data: A tuple of real images and their labels (labels are not used here).\n",
    "\n",
    "        Returns:\n",
    "        - A dictionary containing the current generator loss (g_loss) and discriminator loss (d_loss).\n",
    "        \"\"\"\n",
    "        real_images, _ = data  # Unpack real images (we discard the labels since they aren't needed)\n",
    "\n",
    "        # Ensure real images are in the correct data type (float32)\n",
    "        real_images = tf.cast(real_images, tf.float32)\n",
    "\n",
    "        batch_size = tf.shape(real_images)[0]  # Get the batch size\n",
    "\n",
    "        # Sample random points in the latent space for generator input (latent_dim = 128)\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "\n",
    "        # Generate fake images from random latent vectors\n",
    "        generated_images = self.generator(random_latent_vectors)\n",
    "\n",
    "        # Combine real and fake images into a single batch\n",
    "        combined_images = tf.concat([generated_images, real_images], axis=0)\n",
    "\n",
    "        # Create labels for real (1) and fake (0) images\n",
    "        labels = tf.concat([tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0)\n",
    "\n",
    "        # Add random noise to the labels to introduce label smoothing (makes training more stable)\n",
    "        labels += 0.05 * tf.random.uniform(tf.shape(labels))\n",
    "\n",
    "        # Train the discriminator\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Get predictions from the discriminator for the combined images (real and fake)\n",
    "            predictions = self.discriminator(combined_images)\n",
    "            # Calculate discriminator loss\n",
    "            d_loss = self.loss_fn(labels, predictions)\n",
    "        # Compute gradients for the discriminator\n",
    "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
    "        # Update the discriminator weights using the optimizer\n",
    "        self.d_optimizer.apply_gradients(zip(grads, self.discriminator.trainable_weights))\n",
    "\n",
    "        # Re-sample random points in the latent space for training the generator\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "\n",
    "        # Create \"misleading\" labels (all ones) to trick the discriminator into thinking all generated images are real\n",
    "        misleading_labels = tf.ones((batch_size, 1))\n",
    "\n",
    "        # Train the generator\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Generate new fake images\n",
    "            generated_images = self.generator(random_latent_vectors)\n",
    "            # Get predictions from the discriminator for these fake images\n",
    "            predictions = self.discriminator(generated_images)\n",
    "            # Calculate generator loss (want discriminator to think the generated images are real)\n",
    "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
    "\n",
    "        # Compute gradients for the generator\n",
    "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
    "\n",
    "        # Update the generator weights using the optimizer\n",
    "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
    "\n",
    "        # Update the loss trackers\n",
    "        self.gen_loss_tracker.update_state(g_loss)\n",
    "        self.disc_loss_tracker.update_state(d_loss)\n",
    "\n",
    "        # Return the current losses for generator and discriminator\n",
    "        return {\"g_loss\": self.gen_loss_tracker.result(), \"d_loss\": self.disc_loss_tracker.result()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m312/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - d_loss: -0.8166 - g_loss: 0.0941"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling Sequential.call().\n\n\u001b[1mInvalid input shape for input Tensor(\"Cast:0\", shape=(None, 100, 1, 2), dtype=float32). Expected shape (None, 128), but input has incompatible shape (None, 100, 1, 2)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 100, 1, 2), dtype=float32)\n  • training=None\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[146], line 10\u001b[0m\n\u001b[0;32m      3\u001b[0m gan\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[0;32m      4\u001b[0m     d_optimizer\u001b[38;5;241m=\u001b[39mAdamW(),\n\u001b[0;32m      5\u001b[0m     g_optimizer\u001b[38;5;241m=\u001b[39mAdamW(),\n\u001b[0;32m      6\u001b[0m     loss_fn\u001b[38;5;241m=\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mBinaryCrossentropy(from_logits\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[0;32m      7\u001b[0m )\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Train the GAN model\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[43mgan\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Assuming 20 batches for validation\u001b[39;49;00m\n\u001b[0;32m     14\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;124;03m\"\"\"## Generate and save sample images\"\"\"\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_images\u001b[39m(generator, latent_dim, num_images\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m):\n",
      "File \u001b[1;32md:\\Projects\\Fluid Antennas\\Fluid-Antenna-Channel-Estimation\\.venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "Cell \u001b[1;32mIn[145], line 60\u001b[0m, in \u001b[0;36mGAN.call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;124;03mDefine the forward pass of the GAN model.\u001b[39;00m\n\u001b[0;32m     52\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;124;03m- The output of the generator (fake images).\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     59\u001b[0m latent_vector \u001b[38;5;241m=\u001b[39m inputs  \u001b[38;5;66;03m# Inputs should be the latent vector\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlatent_vector\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling Sequential.call().\n\n\u001b[1mInvalid input shape for input Tensor(\"Cast:0\", shape=(None, 100, 1, 2), dtype=float32). Expected shape (None, 128), but input has incompatible shape (None, 100, 1, 2)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 100, 1, 2), dtype=float32)\n  • training=None\n  • mask=None"
     ]
    }
   ],
   "source": [
    "# Compile the GAN model with AdamW optimizer\n",
    "gan = GAN(discriminator=discriminator, generator=generator, latent_dim=latent_dim)\n",
    "gan.compile(\n",
    "    d_optimizer=AdamW(),\n",
    "    g_optimizer=AdamW(),\n",
    "    loss_fn=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    ")\n",
    "\n",
    "# Train the GAN model\n",
    "gan.fit(\n",
    "    dataset,\n",
    "    epochs=epochs,\n",
    "    validation_data=dataset.take(20)  # Assuming 20 batches for validation\n",
    ")\n",
    "\n",
    "\"\"\"## Generate and save sample images\"\"\"\n",
    "def generate_images(generator, latent_dim, num_images=10):\n",
    "    random_latent_vectors = tf.random.normal(shape=(num_images, latent_dim))\n",
    "    generated_images = generator(random_latent_vectors)\n",
    "    return generated_images.numpy()\n",
    "\n",
    "# Generate images after training\n",
    "fake_images = generate_images(gan.generator, latent_dim)\n",
    "print(\"Generated fake images shape:\", fake_images.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
